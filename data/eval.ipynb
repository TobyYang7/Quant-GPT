{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2018-10-10 09:00:00+08:00\\n时间：2018-10-09 17...</td>\n",
       "      <td>极度负面</td>\n",
       "      <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2018-10-24 09:00:00+08:00\\n时间：2018-10-09 17...</td>\n",
       "      <td>极度负面</td>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2018-12-07 09:00:00+08:00\\n时间：2018-12-06 18...</td>\n",
       "      <td>负面</td>\n",
       "      <td>4949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2018-12-24 09:00:00+08:00\\n时间：2018-12-06 18...</td>\n",
       "      <td>负面</td>\n",
       "      <td>6829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2018-12-24 09:00:00+08:00\\n时间：2018-12-06 18...</td>\n",
       "      <td>负面</td>\n",
       "      <td>8136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-29 19...</td>\n",
       "      <td>正面</td>\n",
       "      <td>4210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...</td>\n",
       "      <td>正面</td>\n",
       "      <td>6582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...</td>\n",
       "      <td>正面</td>\n",
       "      <td>7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...</td>\n",
       "      <td>正面</td>\n",
       "      <td>7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...</td>\n",
       "      <td>现在是2023-04-11 09:00:00+08:00\\n时间：2023-03-30 18...</td>\n",
       "      <td>正面</td>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "1     请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "2     请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "3     请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "4     请根据以下新闻文本，预测三一重工股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "...                                                 ...   \n",
       "5082  请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "5083  请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "5084  请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "5085  请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "5086  请根据以下新闻文本，预测中国建筑股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正...   \n",
       "\n",
       "                                                content label  token  \n",
       "0     现在是2018-10-10 09:00:00+08:00\\n时间：2018-10-09 17...  极度负面   2291  \n",
       "1     现在是2018-10-24 09:00:00+08:00\\n时间：2018-10-09 17...  极度负面   3099  \n",
       "2     现在是2018-12-07 09:00:00+08:00\\n时间：2018-12-06 18...    负面   4949  \n",
       "3     现在是2018-12-24 09:00:00+08:00\\n时间：2018-12-06 18...    负面   6829  \n",
       "4     现在是2018-12-24 09:00:00+08:00\\n时间：2018-12-06 18...    负面   8136  \n",
       "...                                                 ...   ...    ...  \n",
       "5082  现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-29 19...    正面   4210  \n",
       "5083  现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...    正面   6582  \n",
       "5084  现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...    正面   7217  \n",
       "5085  现在是2023-03-31 09:00:00+08:00\\n时间：2023-03-30 18...    正面   7687  \n",
       "5086  现在是2023-04-11 09:00:00+08:00\\n时间：2023-03-30 18...    正面   5918  \n",
       "\n",
       "[5087 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('ft_data_3.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "中性      1031\n",
       "极度负面    1027\n",
       "极度正面    1018\n",
       "负面      1013\n",
       "正面       998\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:724] 2024-05-05 00:40:35,975 >> loading configuration file /home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat/config.json\n",
      "[INFO|configuration_utils.py:724] 2024-05-05 00:40:35,978 >> loading configuration file /home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-05 00:40:35,979 >> Model config QWenConfig {\n",
      "  \"_name_or_path\": \"/home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"QWenLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_qwen.QWenConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_qwen.QWenLMHeadModel\"\n",
      "  },\n",
      "  \"bf16\": true,\n",
      "  \"emb_dropout_prob\": 0.1,\n",
      "  \"fp16\": false,\n",
      "  \"fp32\": false,\n",
      "  \"hidden_size\": 5120,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 27392,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"qwen\",\n",
      "  \"no_bias\": true,\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 40,\n",
      "  \"onnx_safe\": null,\n",
      "  \"padded_vocab_size\": 154112,\n",
      "  \"params_dtype\": \"torch.bfloat16\",\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 1.0,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"seq_length\": 16384,\n",
      "  \"softmax_in_fp32\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_type\": \"QWenTokenizer\",\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_cache_kernel\": false,\n",
      "  \"use_cache_quantization\": false,\n",
      "  \"use_dynamic_ntk\": false,\n",
      "  \"use_flash_attn\": false,\n",
      "  \"use_logn_attn\": false,\n",
      "  \"vocab_size\": 154112\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2085] 2024-05-05 00:40:35,998 >> loading file qwen_finance.tiktoken\n",
      "[INFO|tokenization_utils_base.py:2085] 2024-05-05 00:40:35,999 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2085] 2024-05-05 00:40:35,999 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2085] 2024-05-05 00:40:36,000 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2085] 2024-05-05 00:40:36,001 >> loading file tokenizer.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/05/2024 00:40:36 - INFO - llmtuner.data.template - Add eos token: <|im_end|>\n",
      "05/05/2024 00:40:36 - INFO - llmtuner.data.template - Add pad token: <|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:724] 2024-05-05 00:40:36,613 >> loading configuration file /home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat/config.json\n",
      "[INFO|configuration_utils.py:724] 2024-05-05 00:40:36,615 >> loading configuration file /home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat/config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-05 00:40:36,616 >> Model config QWenConfig {\n",
      "  \"_name_or_path\": \"/home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"QWenLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_qwen.QWenConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_qwen.QWenLMHeadModel\"\n",
      "  },\n",
      "  \"bf16\": true,\n",
      "  \"emb_dropout_prob\": 0.1,\n",
      "  \"fp16\": false,\n",
      "  \"fp32\": false,\n",
      "  \"hidden_size\": 5120,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 27392,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"qwen\",\n",
      "  \"no_bias\": true,\n",
      "  \"num_attention_heads\": 40,\n",
      "  \"num_hidden_layers\": 40,\n",
      "  \"onnx_safe\": null,\n",
      "  \"padded_vocab_size\": 154112,\n",
      "  \"params_dtype\": \"torch.bfloat16\",\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 1.0,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"seq_length\": 16384,\n",
      "  \"softmax_in_fp32\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_type\": \"QWenTokenizer\",\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_cache_kernel\": false,\n",
      "  \"use_cache_quantization\": false,\n",
      "  \"use_dynamic_ntk\": false,\n",
      "  \"use_flash_attn\": false,\n",
      "  \"use_logn_attn\": false,\n",
      "  \"vocab_size\": 154112\n",
      "}\n",
      "\n",
      "2024-05-05 00:40:36,657\tINFO worker.py:1585 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# model_path = \"/home/zhangmin/.cache/modelscope/hub/qwen/Qwen-7B-Chat\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mChatModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqwen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcutoff_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvllm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# top_k=10,\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../train/saves/v2_14b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate_accuracy(model, test_data)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m~/toby/LLaMA-Factory/src/llmtuner/chat/chat_model.py:27\u001b[0m, in \u001b[0;36mChatModel.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m HuggingfaceEngine(model_args, data_args, finetuning_args, generating_args)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_args\u001b[38;5;241m.\u001b[39minfer_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvllm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mVllmEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetuning_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerating_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown backend: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_args\u001b[38;5;241m.\u001b[39minfer_backend))\n",
      "File \u001b[0;32m~/toby/LLaMA-Factory/src/llmtuner/chat/vllm_engine.py:68\u001b[0m, in \u001b[0;36mVllmEngine.__init__\u001b[0;34m(self, model_args, data_args, finetuning_args, generating_args)\u001b[0m\n\u001b[1;32m     65\u001b[0m     engine_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_input_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1,3,336,336\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     engine_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_feature_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_feature_size\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAsyncLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAsyncEngineArgs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_args\u001b[38;5;241m.\u001b[39madapter_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_request \u001b[38;5;241m=\u001b[39m LoRARequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, model_args\u001b[38;5;241m.\u001b[39madapter_name_or_path[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/vllm/engine/async_llm_engine.py:352\u001b[0m, in \u001b[0;36mAsyncLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, start_engine_loop, usage_context)\u001b[0m\n\u001b[1;32m    350\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m CPUExecutorAsync\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine_config\u001b[38;5;241m.\u001b[39mparallel_config\u001b[38;5;241m.\u001b[39mworker_use_ray:\n\u001b[0;32m--> 352\u001b[0m     \u001b[43minitialize_ray_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexecutor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mray_gpu_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RayGPUExecutorAsync\n\u001b[1;32m    354\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m RayGPUExecutorAsync\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/vllm/engine/ray_utils.py:116\u001b[0m, in \u001b[0;36minitialize_ray_cluster\u001b[0;34m(parallel_config, ray_address)\u001b[0m\n\u001b[1;32m    111\u001b[0m     current_placement_group \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mplacement_group(\n\u001b[1;32m    112\u001b[0m         placement_group_specs)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Wait until PG is ready - this will block until all\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# requested resources are available, and will timeout\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# if they cannot be provisioned.\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_placement_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mready\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Set the placement group in the parallel config\u001b[39;00m\n\u001b[1;32m    119\u001b[0m parallel_config\u001b[38;5;241m.\u001b[39mplacement_group \u001b[38;5;241m=\u001b[39m current_placement_group\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/ray/_private/worker.py:2667\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2662\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, is given. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2664\u001b[0m     )\n\u001b[1;32m   2666\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2667\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-2.0/lib/python3.8/site-packages/ray/_private/worker.py:843\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to call `get` on the value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not an ray.ObjectRef.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         )\n\u001b[1;32m    842\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 843\u001b[0m data_metadata_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, metadata \u001b[38;5;129;01min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3483\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:570\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from llmtuner import ChatModel\n",
    "\n",
    "\n",
    "def predict(model, prompt):\n",
    "    query = prompt\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    resp = model.chat(messages, system=\"你需要帮助我判断股票的对数收益率情况，请选出其中的正确答案。\")\n",
    "    return (resp[0].response_text)\n",
    "\n",
    "\n",
    "def evaluate_accuracy(model, test_data):\n",
    "    results = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with tqdm(total=test_data.shape[0]) as pbar:\n",
    "        for _, item in test_data.iterrows():\n",
    "            text_input = f'''{item['prompt']}\\n{item['content']}'''\n",
    "            predicted_response = predict(model, text_input)\n",
    "\n",
    "            expected_response = item['expected']\n",
    "            results.append({\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"content\": item['content'],\n",
    "                \"expected\": expected_response,\n",
    "                \"predicted\": predicted_response\n",
    "            })\n",
    "            total_predictions += 1\n",
    "            if expected_response in predicted_response:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "            pbar.set_description(f\"Accuracy: {accuracy:.2f}\")\n",
    "            pbar.update()\n",
    "\n",
    "    with open('test_dataset/evaluation_results_qwen.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "max_samples = 100\n",
    "test_data = pd.read_json('test_dataset/results.json')\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data[:max_samples]\n",
    "model_path = \"../exp_model/v2\"\n",
    "# model_path = \"/home/zhangmin/.cache/modelscope/hub/qwen/Qwen-7B-Chat\"\n",
    "model_path = \"/home/zhangmin/.cache/modelscope/hub/TongyiFinance/Tongyi-Finance-14B-Chat\"\n",
    "\n",
    "\n",
    "model = ChatModel(dict(\n",
    "    model_name_or_path=model_path,\n",
    "    template=\"qwen\",\n",
    "    temperature=0.5,\n",
    "    cutoff_len=8192,\n",
    "    infer_backend=\"vllm\",\n",
    "    # top_k=10,\n",
    "    adapter_name_or_path='../train/saves/v2_14b',\n",
    "))\n",
    "\n",
    "accuracy = evaluate_accuracy(model, test_data)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
