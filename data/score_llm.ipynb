{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a445e968a44ad19bab2a1ba8e56f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "\n",
    "\n",
    "# def chat(user_input):\n",
    "#     model_path = \"../exp_model/v1\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "#     model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True)\n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": ''},\n",
    "#         {\"role\": \"user\", \"content\": user_input}\n",
    "#     ]\n",
    "\n",
    "#     input_ids = tokenizer.apply_chat_template(\n",
    "#         messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "#     ).to(model.device)\n",
    "\n",
    "#     outputs = model.generate(\n",
    "#         input_ids,\n",
    "#         max_new_tokens=1024,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.5,\n",
    "#         top_p=0.5,\n",
    "#     )\n",
    "#     response = outputs[0][input_ids.shape[-1]:]\n",
    "#     return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "model_path = \"../exp_model/v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    try:\n",
    "        stock_mapping = {\n",
    "            \"600031.SH\": \"三一重工\",\n",
    "            \"600036.SH\": \"招商银行\",\n",
    "            \"600050.SH\": \"中国联通\",\n",
    "            \"600104.SH\": \"上汽集团\",\n",
    "            \"600346.SH\": \"恒力石化\",\n",
    "            \"600570.SH\": \"恒生电子\",\n",
    "            \"600887.SH\": \"伊利股份\",\n",
    "            \"601390.SH\": \"中国中铁\",\n",
    "            \"603160.SH\": \"汇项科技\",\n",
    "            \"601668.SH\": \"中国建筑\"\n",
    "        }\n",
    "        stock = stock_mapping[row['symbol']]\n",
    "        prompt = f\"请根据以下新闻文本，预测{stock}股票的对数收益率属于以下哪一类别 (极度负面/负面/中性/正面/极度正面)\"\n",
    "        label_mapping = {0: \"极度负面\", 1: \"负面\", 2: \"中性\", 3: \"正面\", 4: \"极度正面\"}\n",
    "        label = label_mapping[row['label']]\n",
    "\n",
    "        def chat(user_input):\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": ''},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "\n",
    "            input_ids = tokenizer.apply_chat_template(\n",
    "                messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=1024,\n",
    "                do_sample=True,\n",
    "                temperature=0.5,\n",
    "                top_p=0.5,\n",
    "            )\n",
    "            response = outputs[0][input_ids.shape[-1]:]\n",
    "            return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "        predict = chat(prompt+row['content'])\n",
    "        torch.cuda.empty_cache()\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"content\": row['content'],\n",
    "            \"label\": label,\n",
    "            \"predict\": predict\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_dataset(df, max_samples=32):\n",
    "    df_subset = df.head(max_samples)\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = [executor.submit(process_row, row) for _, row in df_subset.iterrows()]\n",
    "        for future in tqdm(futures, total=len(futures), desc=\"Processing rows\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>log_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2023-04-14 09:00:00</td>\n",
       "      <td>现在是2023-04-14 09:00:00+08:00\\n时间：2023-04-09 17...</td>\n",
       "      <td>-0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2023-04-25 09:00:00</td>\n",
       "      <td>现在是2023-04-25 09:00:00+08:00\\n时间：2023-04-10 18...</td>\n",
       "      <td>-0.031186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2023-04-25 09:00:00</td>\n",
       "      <td>现在是2023-04-25 09:00:00+08:00\\n时间：2023-04-13 23...</td>\n",
       "      <td>-0.031186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2023-04-26 09:00:00</td>\n",
       "      <td>现在是2023-04-26 09:00:00+08:00\\n时间：2023-04-24 09...</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2023-04-26 09:00:00</td>\n",
       "      <td>现在是2023-04-26 09:00:00+08:00\\n时间：2023-04-24 09...</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2024-03-21 09:00:00</td>\n",
       "      <td>现在是2024-03-21 09:00:00+08:00\\n时间：2024-03-20 19...</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2024-03-21 09:00:00</td>\n",
       "      <td>现在是2024-03-21 09:00:00+08:00\\n时间：2024-03-20 19...</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2024-03-25 09:00:00</td>\n",
       "      <td>现在是2024-03-25 09:00:00+08:00\\n时间：2024-03-20 19...</td>\n",
       "      <td>-0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2024-03-29 09:00:00</td>\n",
       "      <td>现在是2024-03-29 09:00:00+08:00\\n时间：2024-03-20 19...</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2024-04-12 09:00:00</td>\n",
       "      <td>现在是2024-04-12 09:00:00+08:00\\n时间：2024-03-22 17...</td>\n",
       "      <td>0.005924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         symbol                time  \\\n",
       "489   600031.SH 2023-04-14 09:00:00   \n",
       "490   600031.SH 2023-04-25 09:00:00   \n",
       "491   600031.SH 2023-04-25 09:00:00   \n",
       "492   600031.SH 2023-04-26 09:00:00   \n",
       "493   600031.SH 2023-04-26 09:00:00   \n",
       "...         ...                 ...   \n",
       "6482  601668.SH 2024-03-21 09:00:00   \n",
       "6483  601668.SH 2024-03-21 09:00:00   \n",
       "6484  601668.SH 2024-03-25 09:00:00   \n",
       "6485  601668.SH 2024-03-29 09:00:00   \n",
       "6486  601668.SH 2024-04-12 09:00:00   \n",
       "\n",
       "                                                content     log_r  \n",
       "489   现在是2023-04-14 09:00:00+08:00\\n时间：2023-04-09 17... -0.015666  \n",
       "490   现在是2023-04-25 09:00:00+08:00\\n时间：2023-04-10 18... -0.031186  \n",
       "491   现在是2023-04-25 09:00:00+08:00\\n时间：2023-04-13 23... -0.031186  \n",
       "492   现在是2023-04-26 09:00:00+08:00\\n时间：2023-04-24 09...  0.005575  \n",
       "493   现在是2023-04-26 09:00:00+08:00\\n时间：2023-04-24 09...  0.005575  \n",
       "...                                                 ...       ...  \n",
       "6482  现在是2024-03-21 09:00:00+08:00\\n时间：2024-03-20 19...  0.005764  \n",
       "6483  现在是2024-03-21 09:00:00+08:00\\n时间：2024-03-20 19...  0.005764  \n",
       "6484  现在是2024-03-25 09:00:00+08:00\\n时间：2024-03-20 19... -0.007707  \n",
       "6485  现在是2024-03-29 09:00:00+08:00\\n时间：2024-03-20 19...  0.001914  \n",
       "6486  现在是2024-04-12 09:00:00+08:00\\n时间：2024-03-22 17...  0.005924  \n",
       "\n",
       "[1400 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet('processed_LLM_data_test_1_3_30.parquet')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        log_r  label\n",
      "489 -0.015666      0\n",
      "490 -0.031186      0\n",
      "491 -0.031186      0\n",
      "492  0.005575      3\n",
      "493  0.005575      3\n"
     ]
    }
   ],
   "source": [
    "data['label'] = pd.qcut(data['log_r'], 5, labels=False)\n",
    "print(data[['log_r', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 0/1400 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (41353 > 32768). Running this sequence through the model will result in indexing errors\n",
      "Processing rows:   0%|          | 3/1400 [00:01<06:35,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 405.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.57 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 6.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.69 GiB of which 253.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 10.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 375.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.60 GiB memory in use. Of the allocated memory 3.08 GiB is allocated by PyTorch, and 230.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 4/1400 [00:01<05:35,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 135.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 2.92 GiB is allocated by PyTorch, and 627.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 284.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 59.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 316.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 59.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 316.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   1%|          | 8/1400 [00:01<02:46,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 237.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 237.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 326.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   1%|          | 11/1400 [00:01<02:32,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 273.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 215.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.24 GiB is allocated by PyTorch, and 362.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 556.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 389.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 549.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 393.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 332.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.19 GiB is allocated by PyTorch, and 412.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 334.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 272.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.15 GiB is allocated by PyTorch, and 454.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 61.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 270.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   1%|          | 13/1400 [00:02<04:56,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 610.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 351.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.62 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 756.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   2%|▏         | 25/1400 [00:04<03:51,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 874.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 490.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.14 GiB memory in use. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 324.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   2%|▏         | 28/1400 [00:04<03:23,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 73.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 161.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 183.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 342.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   2%|▏         | 30/1400 [00:05<05:02,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.11 GiB. GPU 3 has a total capacity of 23.69 GiB of which 450.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.18 GiB memory in use. Of the allocated memory 5.68 GiB is allocated by PyTorch, and 196.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   2%|▏         | 32/1400 [00:06<05:38,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 33.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 577.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 818.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 758.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 5.88 GiB memory in use. Of the allocated memory 5.37 GiB is allocated by PyTorch, and 207.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 275.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.69 GiB memory in use. Of the allocated memory 2.83 GiB is allocated by PyTorch, and 566.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 275.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.69 GiB memory in use. Of the allocated memory 2.84 GiB is allocated by PyTorch, and 555.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   3%|▎         | 36/1400 [00:06<04:28,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.47 GiB is allocated by PyTorch, and 148.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.47 GiB is allocated by PyTorch, and 144.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   3%|▎         | 38/1400 [00:07<05:02,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 2.53 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 680.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 2.91 GiB is allocated by PyTorch, and 713.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 44.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.58 GiB memory in use. Of the allocated memory 6.01 GiB is allocated by PyTorch, and 261.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   3%|▎         | 45/1400 [00:08<04:10,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 123.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 198.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 123.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 198.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 125.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 212.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 125.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, and 482.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 211.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 3.15 GiB is allocated by PyTorch, and 305.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 55.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.53 GiB is allocated by PyTorch, and 69.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1018.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 44.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.58 GiB memory in use. Of the allocated memory 5.56 GiB is allocated by PyTorch, and 723.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   4%|▎         | 52/1400 [00:10<03:34,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 33.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.55 GiB is allocated by PyTorch, and 65.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 33.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.55 GiB is allocated by PyTorch, and 65.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 150.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 149.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 177.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 79.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.53 GiB is allocated by PyTorch, and 74.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   4%|▍         | 58/1400 [00:10<02:14,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 290.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 77.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 283.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 77.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 283.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 77.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 238.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 155.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.81 GiB memory in use. Of the allocated memory 3.04 GiB is allocated by PyTorch, and 471.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   5%|▍         | 64/1400 [00:10<01:39, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 155.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.81 GiB memory in use. Of the allocated memory 3.24 GiB is allocated by PyTorch, and 266.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 155.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.81 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 116.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 381.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.43 GiB is allocated by PyTorch, and 195.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 296.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 296.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 352.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 430.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.20 GiB is allocated by PyTorch, and 437.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   5%|▍         | 67/1400 [00:12<05:26,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 28.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 6.04 GiB is allocated by PyTorch, and 243.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 265.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.45 GiB is allocated by PyTorch, and 179.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.08 GiB is allocated by PyTorch, and 558.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 188.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 365.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 860.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 28.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 564.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 28.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 6.03 GiB is allocated by PyTorch, and 259.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   5%|▌         | 70/1400 [00:15<10:54,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 353.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 353.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   6%|▌         | 81/1400 [00:16<04:35,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 29.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 203.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 8.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.08 GiB is allocated by PyTorch, and 224.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 7.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.96 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 646.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 9.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 308.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 209.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 439.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   6%|▋         | 89/1400 [00:18<04:20,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.54 GiB is allocated by PyTorch, and 58.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.52 GiB is allocated by PyTorch, and 86.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 247.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 2.81 GiB is allocated by PyTorch, and 612.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1018.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 245.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 292.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   6%|▋         | 91/1400 [00:18<04:29,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 552.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 245.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 2.61 GiB is allocated by PyTorch, and 822.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   7%|▋         | 93/1400 [00:19<05:47,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 496.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 333.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.64 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 93.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 55.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.49 GiB is allocated by PyTorch, and 106.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 542.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 55.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.49 GiB is allocated by PyTorch, and 106.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   7%|▋         | 97/1400 [00:20<06:29,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 50.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.57 GiB memory in use. Of the allocated memory 6.06 GiB is allocated by PyTorch, and 207.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 16.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.21 GiB is allocated by PyTorch, and 86.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 506.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 291.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.02 GiB is allocated by PyTorch, and 355.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 251.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.29 GiB is allocated by PyTorch, and 326.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   7%|▋         | 99/1400 [00:23<11:11,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 102.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 70.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.55 GiB memory in use. Of the allocated memory 5.84 GiB is allocated by PyTorch, and 409.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 106/1400 [00:23<05:39,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 201.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 5.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.96 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 203.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 13.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 13.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 288.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 110/1400 [00:24<03:51,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 81.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 462.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 207.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.45 GiB is allocated by PyTorch, and 138.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 303.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.44 GiB is allocated by PyTorch, and 169.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 113/1400 [00:25<05:32,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 80.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 6.08 GiB is allocated by PyTorch, and 158.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 40.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.58 GiB memory in use. Of the allocated memory 6.14 GiB is allocated by PyTorch, and 137.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 480.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 237.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.73 GiB memory in use. Of the allocated memory 2.69 GiB is allocated by PyTorch, and 747.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 115/1400 [00:26<08:20,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 30.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 6.05 GiB is allocated by PyTorch, and 231.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 648.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 237.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.73 GiB memory in use. Of the allocated memory 2.82 GiB is allocated by PyTorch, and 611.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 118/1400 [00:28<08:39,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 612.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 30.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.59 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 861.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 722.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 340.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.29 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 521.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 119/1400 [00:29<11:29,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 91.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.87 GiB memory in use. Of the allocated memory 3.19 GiB is allocated by PyTorch, and 376.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 91.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.87 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 319.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   9%|▊         | 121/1400 [00:30<09:18,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 730.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 489.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 641.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   9%|▉         | 124/1400 [00:31<09:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 18.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.60 GiB memory in use. Of the allocated memory 6.03 GiB is allocated by PyTorch, and 264.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 18.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.60 GiB memory in use. Of the allocated memory 6.05 GiB is allocated by PyTorch, and 243.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   9%|▉         | 126/1400 [00:31<08:10,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacity of 23.69 GiB of which 905.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.08 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 447.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 23.69 GiB of which 905.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.08 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 445.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 129.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 107.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   9%|▉         | 130/1400 [00:33<07:20,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacity of 23.69 GiB of which 129.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 2.79 GiB is allocated by PyTorch, and 748.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 31.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 284.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 31.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 243.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 80.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 373.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  10%|▉         | 133/1400 [00:34<06:51,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 456.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 347.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.62 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 195.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  10%|▉         | 134/1400 [00:34<07:57,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  10%|▉         | 137/1400 [00:36<07:56,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 528.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 497.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.85 GiB is allocated by PyTorch, and 314.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 55.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.43 GiB is allocated by PyTorch, and 170.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 55.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.50 GiB is allocated by PyTorch, and 100.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  11%|█         | 151/1400 [00:43<12:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  11%|█         | 153/1400 [00:44<11:35,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  11%|█         | 154/1400 [00:45<11:50,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  11%|█▏        | 160/1400 [00:47<08:52,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 488.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 309.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.66 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 227.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 87.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 322.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 5.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.96 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 274.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  12%|█▏        | 161/1400 [00:49<13:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 251.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.72 GiB memory in use. Of the allocated memory 2.97 GiB is allocated by PyTorch, and 439.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.15 GiB. GPU 3 has a total capacity of 23.69 GiB of which 478.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.15 GiB memory in use. Of the allocated memory 5.72 GiB is allocated by PyTorch, and 126.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  12%|█▏        | 165/1400 [00:49<07:21,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 2.23 GiB. GPU 0 has a total capacity of 23.69 GiB of which 781.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.20 GiB memory in use. Of the allocated memory 2.35 GiB is allocated by PyTorch, and 547.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacity of 23.69 GiB of which 781.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.20 GiB memory in use. Of the allocated memory 2.36 GiB is allocated by PyTorch, and 533.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 23.69 GiB of which 781.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.20 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 556.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  12%|█▏        | 167/1400 [00:50<06:49,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 3.40 GiB. GPU 0 has a total capacity of 23.69 GiB of which 781.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.20 GiB memory in use. Of the allocated memory 2.45 GiB is allocated by PyTorch, and 441.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 59.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.56 GiB is allocated by PyTorch, and 34.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacity of 23.69 GiB of which 37.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 500.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  12%|█▏        | 173/1400 [00:51<04:02,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacity of 23.69 GiB of which 477.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.50 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 60.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 124.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 123.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 471.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  13%|█▎        | 176/1400 [00:51<03:01,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.47 GiB is allocated by PyTorch, and 131.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 351.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 966.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 624.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.01 GiB memory in use. Of the allocated memory 5.51 GiB is allocated by PyTorch, and 193.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  13%|█▎        | 178/1400 [00:53<06:32,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 2.89 GiB is allocated by PyTorch, and 724.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  13%|█▎        | 180/1400 [00:53<05:46,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 51.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.10 GiB is allocated by PyTorch, and 512.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 339.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.63 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 426.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 3 has a total capacity of 23.69 GiB of which 616.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.02 GiB memory in use. Of the allocated memory 5.58 GiB is allocated by PyTorch, and 127.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 180.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 181.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 536.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 57.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 2.80 GiB is allocated by PyTorch, and 806.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 528.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 770.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 584.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 133.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 2.82 GiB is allocated by PyTorch, and 715.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 131.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 134.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 394.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 131.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.83 GiB memory in use. Of the allocated memory 3.16 GiB is allocated by PyTorch, and 370.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 209.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 2.99 GiB is allocated by PyTorch, and 465.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 209.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 2.80 GiB is allocated by PyTorch, and 662.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 232.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 69.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 472.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 69.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 231.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  13%|█▎        | 183/1400 [00:55<07:49,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 157.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.81 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 291.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  14%|█▍        | 196/1400 [00:56<04:11,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 42.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.58 GiB memory in use. Of the allocated memory 6.01 GiB is allocated by PyTorch, and 261.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  14%|█▍        | 200/1400 [00:57<03:27,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 37.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 338.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.29 GiB is allocated by PyTorch, and 323.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 39.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.29 GiB is allocated by PyTorch, and 323.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  15%|█▍        | 205/1400 [01:00<07:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 11.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.46 GiB is allocated by PyTorch, and 181.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 43.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 193.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 123.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 301.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 13.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.19 GiB is allocated by PyTorch, and 458.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  15%|█▍        | 206/1400 [01:01<10:36,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 73.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 222.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  15%|█▌        | 211/1400 [01:02<05:44,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 73.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 302.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 73.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 409.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 12.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.13 GiB is allocated by PyTorch, and 168.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 12.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.16 GiB is allocated by PyTorch, and 142.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 694.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 460.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.17 GiB memory in use. Of the allocated memory 5.68 GiB is allocated by PyTorch, and 187.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 73.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 311.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 13.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 363.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 259.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 2.47 GiB is allocated by PyTorch, and 946.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  16%|█▌        | 221/1400 [01:04<04:23,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 579.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 770.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 990.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 579.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 770.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 93.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.87 GiB memory in use. Of the allocated memory 3.19 GiB is allocated by PyTorch, and 374.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 820.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 564.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Of the allocated memory 5.57 GiB is allocated by PyTorch, and 191.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  16%|█▌        | 224/1400 [01:06<06:54,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 878.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 456.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.18 GiB memory in use. Of the allocated memory 5.52 GiB is allocated by PyTorch, and 346.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 23.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 270.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 23.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 348.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  17%|█▋        | 232/1400 [01:07<04:22,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.06 GiB. GPU 3 has a total capacity of 23.69 GiB of which 528.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.63 GiB is allocated by PyTorch, and 169.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 111.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.85 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 292.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 27.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 235.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 157.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.81 GiB memory in use. Of the allocated memory 3.07 GiB is allocated by PyTorch, and 431.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 79.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 267.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  17%|█▋        | 234/1400 [01:08<03:49,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 494.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 129.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.10 GiB is allocated by PyTorch, and 430.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 129.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.84 GiB memory in use. Of the allocated memory 3.10 GiB is allocated by PyTorch, and 430.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 214.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.09 GiB is allocated by PyTorch, and 520.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  17%|█▋        | 241/1400 [01:08<02:10,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 340.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 49.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 340.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 217.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.75 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 325.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 217.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.75 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 174.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 217.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.75 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, and 381.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 226.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 170.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 191.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 248.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 560.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 526.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.53 GiB is allocated by PyTorch, and 272.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  18%|█▊        | 249/1400 [01:10<03:52,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 700.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 689.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.80 GiB is allocated by PyTorch, and 175.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 38.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.58 GiB memory in use. Of the allocated memory 6.13 GiB is allocated by PyTorch, and 149.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  18%|█▊        | 251/1400 [01:11<04:26,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: CUDA out of memory. Tried to allocate 498.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 289.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 154.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 8.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.14 GiB is allocated by PyTorch, and 168.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  18%|█▊        | 258/1400 [01:12<03:10,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 274.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 233.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 53.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 255.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 53.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 255.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 143.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.82 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 182.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  19%|█▊        | 260/1400 [01:13<03:01,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.28 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.16 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 2.81 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 159.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.16 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 2.81 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 155.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  19%|█▉        | 264/1400 [01:13<03:04,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.15 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 2.81 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 155.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 23.69 GiB of which 413.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.56 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 20.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 424.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 389.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.58 GiB memory in use. Of the allocated memory 2.84 GiB is allocated by PyTorch, and 438.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 89.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.29 GiB is allocated by PyTorch, and 277.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  19%|█▉        | 266/1400 [01:13<02:38,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 796.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 203.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 3.10 GiB is allocated by PyTorch, and 354.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 802.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 203.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.76 GiB memory in use. Of the allocated memory 3.20 GiB is allocated by PyTorch, and 255.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 13.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.43 GiB is allocated by PyTorch, and 208.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  19%|█▉        | 271/1400 [01:14<01:51, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 376.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 301.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 460.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 334.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 278.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  20%|█▉        | 274/1400 [01:14<01:43, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 246.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.39 GiB is allocated by PyTorch, and 246.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.19 GiB is allocated by PyTorch, and 457.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 239.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  20%|██        | 281/1400 [01:16<03:26,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 20.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.60 GiB memory in use. Of the allocated memory 6.15 GiB is allocated by PyTorch, and 143.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 56.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.57 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 142.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 259.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 343.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 318.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  20%|██        | 283/1400 [01:16<02:56,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 572.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 2.73 GiB is allocated by PyTorch, and 924.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  20%|██        | 285/1400 [01:17<04:42,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 686.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 248.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.38 GiB memory in use. Of the allocated memory 5.24 GiB is allocated by PyTorch, and 850.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 56.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.57 GiB memory in use. Of the allocated memory 5.96 GiB is allocated by PyTorch, and 298.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  21%|██        | 291/1400 [01:18<03:14,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 239.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 341.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 302.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 319.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 319.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.46 GiB is allocated by PyTorch, and 173.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.46 GiB is allocated by PyTorch, and 173.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  21%|██        | 293/1400 [01:20<05:24,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 836.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 324.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.30 GiB memory in use. Of the allocated memory 5.76 GiB is allocated by PyTorch, and 235.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 78.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.54 GiB memory in use. Of the allocated memory 5.98 GiB is allocated by PyTorch, and 257.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 25.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.29 GiB is allocated by PyTorch, and 335.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 89.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.24 GiB is allocated by PyTorch, and 328.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  21%|██        | 295/1400 [01:22<10:41,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 75.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.35 GiB is allocated by PyTorch, and 230.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  22%|██▏       | 305/1400 [01:23<04:07,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 295.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 992.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 600.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.04 GiB memory in use. Of the allocated memory 5.54 GiB is allocated by PyTorch, and 191.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 107.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.86 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 300.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 107.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.86 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 215.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.07 GiB is allocated by PyTorch, and 525.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  22%|██▏       | 308/1400 [01:23<03:20,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 264.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 63.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 264.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 31.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.30 GiB is allocated by PyTorch, and 323.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 31.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 248.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  22%|██▏       | 310/1400 [01:23<02:53,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 31.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.93 GiB memory in use. Of the allocated memory 3.08 GiB is allocated by PyTorch, and 548.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 111.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.85 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 206.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 111.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.85 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 206.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  23%|██▎       | 316/1400 [01:24<01:54,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 460.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 65.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 254.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 472.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 65.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.34 GiB is allocated by PyTorch, and 254.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 418.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.07 GiB is allocated by PyTorch, and 528.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 67.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.90 GiB memory in use. Of the allocated memory 3.09 GiB is allocated by PyTorch, and 505.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 539.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.85 GiB is allocated by PyTorch, and 277.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  23%|██▎       | 318/1400 [01:25<04:35,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 948.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 250.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.38 GiB memory in use. Of the allocated memory 5.49 GiB is allocated by PyTorch, and 585.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 315.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 328.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.31 GiB is allocated by PyTorch, and 328.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.03 GiB. GPU 3 has a total capacity of 23.69 GiB of which 540.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Of the allocated memory 5.60 GiB is allocated by PyTorch, and 188.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  23%|██▎       | 324/1400 [01:27<05:15,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 520.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.03 GiB. GPU 3 has a total capacity of 23.69 GiB of which 346.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.28 GiB memory in use. Of the allocated memory 5.59 GiB is allocated by PyTorch, and 386.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.36 GiB is allocated by PyTorch, and 281.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.42 GiB is allocated by PyTorch, and 215.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 15.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.95 GiB memory in use. Of the allocated memory 3.25 GiB is allocated by PyTorch, and 393.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  23%|██▎       | 328/1400 [01:28<03:32,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 612.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 71.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.89 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 305.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  24%|██▎       | 330/1400 [01:28<03:38,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.04 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 2.93 GiB memory in use. Of the allocated memory 2.40 GiB is allocated by PyTorch, and 220.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.04 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 2.93 GiB memory in use. Of the allocated memory 2.40 GiB is allocated by PyTorch, and 216.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  24%|██▎       | 332/1400 [01:29<04:36,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacity of 23.69 GiB of which 941.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.04 GiB memory in use. Of the allocated memory 2.60 GiB is allocated by PyTorch, and 131.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 882.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 346.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.28 GiB memory in use. Of the allocated memory 5.43 GiB is allocated by PyTorch, and 556.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.01 GiB. GPU 3 has a total capacity of 23.69 GiB of which 462.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.17 GiB memory in use. Of the allocated memory 5.57 GiB is allocated by PyTorch, and 291.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  24%|██▍       | 333/1400 [01:31<07:56,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 810.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 330.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.30 GiB memory in use. Of the allocated memory 5.36 GiB is allocated by PyTorch, and 642.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 81.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 191.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 5.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.96 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 245.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 5.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.96 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 248.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 836.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 357.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.61 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 404.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 359.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.61 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 747.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 452.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 357.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.61 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 748.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 179.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.79 GiB memory in use. Of the allocated memory 3.20 GiB is allocated by PyTorch, and 281.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 97.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.87 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 280.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 97.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.87 GiB memory in use. Of the allocated memory 3.15 GiB is allocated by PyTorch, and 408.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  24%|██▍       | 335/1400 [01:33<10:54,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 558.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 482.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.15 GiB memory in use. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 742.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  25%|██▍       | 346/1400 [01:34<04:24,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 976.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 482.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.15 GiB memory in use. Of the allocated memory 5.52 GiB is allocated by PyTorch, and 327.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 45.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 354.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  25%|██▍       | 347/1400 [01:35<05:37,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 45.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 474.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 45.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 342.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.07 GiB. GPU 3 has a total capacity of 23.69 GiB of which 530.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 159.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  25%|██▌       | 353/1400 [01:36<04:18,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 45.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.27 GiB is allocated by PyTorch, and 336.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 866.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 530.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Of the allocated memory 5.41 GiB is allocated by PyTorch, and 388.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 277.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 277.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.11 GiB is allocated by PyTorch, and 506.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 393.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 47.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.92 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 393.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 19.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 18.10 GiB memory in use. Including non-PyTorch memory, this process has 3.94 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  26%|██▌       | 359/1400 [01:37<03:38,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 836.00 MiB. GPU 3 has a total capacity of 23.69 GiB of which 530.06 MiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Of the allocated memory 5.38 GiB is allocated by PyTorch, and 417.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  26%|██▌       | 364/1400 [01:43<13:24,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  26%|██▌       | 365/1400 [01:44<13:20,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: The expanded size of the tensor (131068) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 131068, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.05 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 18.02 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 23.69 GiB of which 223.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 18.85 GiB memory in use. Of the allocated memory 14.84 GiB is allocated by PyTorch, and 3.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  27%|██▋       | 382/1400 [02:07<39:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  28%|██▊       | 385/1400 [02:20<1:01:02,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  28%|██▊       | 386/1400 [02:28<1:18:16,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  28%|██▊       | 394/1400 [02:31<24:38,  1.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  28%|██▊       | 395/1400 [02:31<23:26,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  28%|██▊       | 396/1400 [02:32<20:49,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  29%|██▊       | 401/1400 [02:39<20:40,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  29%|██▉       | 404/1400 [02:44<23:41,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  29%|██▉       | 405/1400 [02:49<38:47,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 5.29 GiB. GPU 3 has a total capacity of 23.69 GiB of which 4.23 GiB is free. Process 602017 has 368.00 MiB memory in use. Process 2745936 has 4.50 GiB memory in use. Including non-PyTorch memory, this process has 14.58 GiB memory in use. Of the allocated memory 12.52 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 924.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 697.00 MiB is free. Process 2745936 has 5.74 GiB memory in use. Including non-PyTorch memory, this process has 17.26 GiB memory in use. Of the allocated memory 13.25 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 946.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 827.00 MiB is free. Process 2745936 has 5.74 GiB memory in use. Including non-PyTorch memory, this process has 17.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  29%|██▉       | 412/1400 [03:15<47:09,  2.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  30%|███       | 421/1400 [03:39<38:38,  2.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  31%|███       | 429/1400 [03:55<37:42,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: The expanded size of the tensor (44191) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 44191, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (44064) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 44064, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (46896) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 46896, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  31%|███       | 430/1400 [03:58<39:14,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  31%|███       | 435/1400 [03:59<14:51,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 4.38 GiB. GPU 0 has a total capacity of 23.69 GiB of which 4.35 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 14.72 GiB memory in use. Of the allocated memory 10.01 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  31%|███       | 436/1400 [03:59<13:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.42 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 17.66 GiB memory in use. Of the allocated memory 17.32 GiB is allocated by PyTorch, and 20.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.42 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 17.66 GiB memory in use. Of the allocated memory 17.33 GiB is allocated by PyTorch, and 16.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  31%|███▏      | 440/1400 [04:05<19:31,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  32%|███▏      | 444/1400 [04:31<1:35:19,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: CUDA out of memory. Tried to allocate 350.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 97.00 MiB is free. Process 2745936 has 5.74 GiB memory in use. Including non-PyTorch memory, this process has 17.84 GiB memory in use. Of the allocated memory 15.16 GiB is allocated by PyTorch, and 2.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  32%|███▏      | 446/1400 [04:52<2:06:11,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 233.00 MiB is free. Process 2745936 has 5.74 GiB memory in use. Including non-PyTorch memory, this process has 17.71 GiB memory in use. Of the allocated memory 15.03 GiB is allocated by PyTorch, and 2.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  32%|███▏      | 453/1400 [05:02<56:47,  3.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  33%|███▎      | 460/1400 [05:16<38:10,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  33%|███▎      | 463/1400 [05:22<35:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  33%|███▎      | 465/1400 [05:25<32:06,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  33%|███▎      | 467/1400 [05:26<25:05,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 2.69 GiB. GPU 0 has a total capacity of 23.69 GiB of which 2.58 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 16.49 GiB memory in use. Of the allocated memory 13.76 GiB is allocated by PyTorch, and 2.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacity of 23.69 GiB of which 2.58 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 16.49 GiB memory in use. Of the allocated memory 13.76 GiB is allocated by PyTorch, and 2.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: The expanded size of the tensor (34759) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 34759, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  34%|███▎      | 469/1400 [05:26<19:18,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 2.65 GiB. GPU 0 has a total capacity of 23.69 GiB of which 2.58 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 2.99 GiB memory in use. Including non-PyTorch memory, this process has 16.49 GiB memory in use. Of the allocated memory 13.89 GiB is allocated by PyTorch, and 2.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: The expanded size of the tensor (35515) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 35515, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (48545) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 48545, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  34%|███▍      | 473/1400 [05:37<29:24,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: CUDA out of memory. Tried to allocate 420.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 285.00 MiB is free. Process 2745936 has 5.66 GiB memory in use. Including non-PyTorch memory, this process has 17.73 GiB memory in use. Of the allocated memory 14.66 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 41.00 MiB is free. Process 2745936 has 5.66 GiB memory in use. Including non-PyTorch memory, this process has 17.97 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  34%|███▍      | 474/1400 [05:42<11:08,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: probability tensor contains either `inf`, `nan` or element < 0\n",
      "Error processing row: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 1 has a total capacity of 23.69 GiB of which 397.00 MiB is free. Process 2745936 has 5.66 GiB memory in use. Including non-PyTorch memory, this process has 17.62 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: The expanded size of the tensor (35090) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 35090, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (34402) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 34402, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (57268) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 57268, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: The expanded size of the tensor (93031) must match the existing size (32767) at non-singleton dimension 1.  Target sizes: [1, 93031, 32, 128].  Tensor sizes: [1, 32767, 1, 1]\n",
      "Error processing row: CUDA out of memory. Tried to allocate 3.36 GiB. GPU 0 has a total capacity of 23.69 GiB of which 849.12 MiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 3.72 GiB memory in use. Including non-PyTorch memory, this process has 17.51 GiB memory in use. Of the allocated memory 11.53 GiB is allocated by PyTorch, and 5.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Error processing row: CUDA out of memory. Tried to allocate 2.76 GiB. GPU 0 has a total capacity of 23.69 GiB of which 1.24 GiB is free. Process 2068527 has 440.00 MiB memory in use. Process 2357580 has 1.17 GiB memory in use. Process 2745936 has 3.72 GiB memory in use. Including non-PyTorch memory, this process has 17.10 GiB memory in use. Of the allocated memory 13.19 GiB is allocated by PyTorch, and 3.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "processed_data = generate_dataset(data, max_samples=10000)\n",
    "output_file_path = 'ft_data_score_result.json'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
