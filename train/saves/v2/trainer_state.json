{
  "best_metric": 0.625176727771759,
  "best_model_checkpoint": "/root/autodl-tmp/saves/v2/checkpoint-1500",
  "epoch": 1.9988499137435307,
  "eval_steps": 500,
  "global_step": 1738,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005750431282346176,
      "grad_norm": NaN,
      "learning_rate": 6.896551724137931e-07,
      "loss": 6.2324,
      "step": 5
    },
    {
      "epoch": 0.011500862564692352,
      "grad_norm": NaN,
      "learning_rate": 2.068965517241379e-06,
      "loss": 4.454,
      "step": 10
    },
    {
      "epoch": 0.017251293847038527,
      "grad_norm": 11.130380630493164,
      "learning_rate": 3.7931034482758625e-06,
      "loss": 4.2022,
      "step": 15
    },
    {
      "epoch": 0.023001725129384705,
      "grad_norm": 11.716176986694336,
      "learning_rate": 5.517241379310345e-06,
      "loss": 5.0243,
      "step": 20
    },
    {
      "epoch": 0.02875215641173088,
      "grad_norm": 8.693259239196777,
      "learning_rate": 7.241379310344828e-06,
      "loss": 4.5633,
      "step": 25
    },
    {
      "epoch": 0.034502587694077054,
      "grad_norm": 12.16523551940918,
      "learning_rate": 8.965517241379312e-06,
      "loss": 5.7305,
      "step": 30
    },
    {
      "epoch": 0.04025301897642323,
      "grad_norm": 18.630603790283203,
      "learning_rate": 1.0689655172413794e-05,
      "loss": 3.3405,
      "step": 35
    },
    {
      "epoch": 0.04600345025876941,
      "grad_norm": 16.624393463134766,
      "learning_rate": 1.2068965517241379e-05,
      "loss": 3.6166,
      "step": 40
    },
    {
      "epoch": 0.051753881541115584,
      "grad_norm": 6.175773620605469,
      "learning_rate": 1.3793103448275862e-05,
      "loss": 2.7652,
      "step": 45
    },
    {
      "epoch": 0.05750431282346176,
      "grad_norm": 10.206504821777344,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 2.2633,
      "step": 50
    },
    {
      "epoch": 0.06325474410580793,
      "grad_norm": 15.551602363586426,
      "learning_rate": 1.7241379310344828e-05,
      "loss": 1.8204,
      "step": 55
    },
    {
      "epoch": 0.06900517538815411,
      "grad_norm": 5.96877384185791,
      "learning_rate": 1.896551724137931e-05,
      "loss": 0.9491,
      "step": 60
    },
    {
      "epoch": 0.07475560667050028,
      "grad_norm": 8.454343795776367,
      "learning_rate": 2.0689655172413797e-05,
      "loss": 1.6305,
      "step": 65
    },
    {
      "epoch": 0.08050603795284646,
      "grad_norm": 8.486859321594238,
      "learning_rate": 2.2413793103448276e-05,
      "loss": 0.9846,
      "step": 70
    },
    {
      "epoch": 0.08625646923519265,
      "grad_norm": 9.066577911376953,
      "learning_rate": 2.4137931034482758e-05,
      "loss": 1.0592,
      "step": 75
    },
    {
      "epoch": 0.09200690051753882,
      "grad_norm": 5.136215686798096,
      "learning_rate": 2.586206896551724e-05,
      "loss": 0.9649,
      "step": 80
    },
    {
      "epoch": 0.097757331799885,
      "grad_norm": 10.845136642456055,
      "learning_rate": 2.7586206896551723e-05,
      "loss": 0.9113,
      "step": 85
    },
    {
      "epoch": 0.10350776308223117,
      "grad_norm": 8.22269058227539,
      "learning_rate": 2.931034482758621e-05,
      "loss": 0.9055,
      "step": 90
    },
    {
      "epoch": 0.10925819436457734,
      "grad_norm": 9.727873802185059,
      "learning_rate": 2.9999755596065908e-05,
      "loss": 1.335,
      "step": 95
    },
    {
      "epoch": 0.11500862564692352,
      "grad_norm": 7.922450065612793,
      "learning_rate": 2.9998262045311014e-05,
      "loss": 0.8451,
      "step": 100
    },
    {
      "epoch": 0.12075905692926969,
      "grad_norm": 7.959473133087158,
      "learning_rate": 2.9995410858796248e-05,
      "loss": 0.6897,
      "step": 105
    },
    {
      "epoch": 0.12650948821161587,
      "grad_norm": 4.257131576538086,
      "learning_rate": 2.9991202294609698e-05,
      "loss": 0.7457,
      "step": 110
    },
    {
      "epoch": 0.13225991949396204,
      "grad_norm": 8.210631370544434,
      "learning_rate": 2.998563673370866e-05,
      "loss": 0.8567,
      "step": 115
    },
    {
      "epoch": 0.13801035077630822,
      "grad_norm": 8.350495338439941,
      "learning_rate": 2.9978714679885137e-05,
      "loss": 0.5877,
      "step": 120
    },
    {
      "epoch": 0.1437607820586544,
      "grad_norm": 12.384476661682129,
      "learning_rate": 2.997043675972024e-05,
      "loss": 1.1144,
      "step": 125
    },
    {
      "epoch": 0.14951121334100057,
      "grad_norm": 3.940777063369751,
      "learning_rate": 2.9960803722527487e-05,
      "loss": 0.7246,
      "step": 130
    },
    {
      "epoch": 0.15526164462334674,
      "grad_norm": 5.730550765991211,
      "learning_rate": 2.994981644028496e-05,
      "loss": 0.906,
      "step": 135
    },
    {
      "epoch": 0.16101207590569291,
      "grad_norm": 7.991091728210449,
      "learning_rate": 2.993747590755638e-05,
      "loss": 0.7603,
      "step": 140
    },
    {
      "epoch": 0.16676250718803912,
      "grad_norm": 7.754329681396484,
      "learning_rate": 2.9923783241401073e-05,
      "loss": 0.693,
      "step": 145
    },
    {
      "epoch": 0.1725129384703853,
      "grad_norm": 6.064385414123535,
      "learning_rate": 2.9908739681272862e-05,
      "loss": 0.7487,
      "step": 150
    },
    {
      "epoch": 0.17826336975273147,
      "grad_norm": 5.244692325592041,
      "learning_rate": 2.989234658890787e-05,
      "loss": 0.6627,
      "step": 155
    },
    {
      "epoch": 0.18401380103507764,
      "grad_norm": 7.109655857086182,
      "learning_rate": 2.9874605448201247e-05,
      "loss": 0.8434,
      "step": 160
    },
    {
      "epoch": 0.18976423231742381,
      "grad_norm": 4.255604267120361,
      "learning_rate": 2.9855517865072874e-05,
      "loss": 0.7099,
      "step": 165
    },
    {
      "epoch": 0.19551466359977,
      "grad_norm": 3.8028926849365234,
      "learning_rate": 2.983508556732196e-05,
      "loss": 0.6323,
      "step": 170
    },
    {
      "epoch": 0.20126509488211616,
      "grad_norm": 4.7382283210754395,
      "learning_rate": 2.9813310404470676e-05,
      "loss": 0.7745,
      "step": 175
    },
    {
      "epoch": 0.20701552616446234,
      "grad_norm": 10.891471862792969,
      "learning_rate": 2.979019434759671e-05,
      "loss": 0.7353,
      "step": 180
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 7.331592082977295,
      "learning_rate": 2.9765739489154868e-05,
      "loss": 0.6235,
      "step": 185
    },
    {
      "epoch": 0.2185163887291547,
      "grad_norm": 4.793477535247803,
      "learning_rate": 2.973994804278765e-05,
      "loss": 0.6025,
      "step": 190
    },
    {
      "epoch": 0.22426682001150086,
      "grad_norm": 7.603575229644775,
      "learning_rate": 2.9712822343124883e-05,
      "loss": 0.7512,
      "step": 195
    },
    {
      "epoch": 0.23001725129384704,
      "grad_norm": 4.433423042297363,
      "learning_rate": 2.9684364845572376e-05,
      "loss": 0.5921,
      "step": 200
    },
    {
      "epoch": 0.2357676825761932,
      "grad_norm": 7.03345251083374,
      "learning_rate": 2.9654578126089686e-05,
      "loss": 0.6443,
      "step": 205
    },
    {
      "epoch": 0.24151811385853938,
      "grad_norm": 3.9601073265075684,
      "learning_rate": 2.962346488095692e-05,
      "loss": 0.6535,
      "step": 210
    },
    {
      "epoch": 0.24726854514088556,
      "grad_norm": 6.412306785583496,
      "learning_rate": 2.959102792653066e-05,
      "loss": 0.6769,
      "step": 215
    },
    {
      "epoch": 0.25301897642323173,
      "grad_norm": 6.453019618988037,
      "learning_rate": 2.955727019898906e-05,
      "loss": 0.9154,
      "step": 220
    },
    {
      "epoch": 0.25876940770557794,
      "grad_norm": 9.495786666870117,
      "learning_rate": 2.9522194754066033e-05,
      "loss": 0.6827,
      "step": 225
    },
    {
      "epoch": 0.2645198389879241,
      "grad_norm": 5.600240707397461,
      "learning_rate": 2.948580476677468e-05,
      "loss": 0.8509,
      "step": 230
    },
    {
      "epoch": 0.2702702702702703,
      "grad_norm": 3.9040472507476807,
      "learning_rate": 2.9448103531119858e-05,
      "loss": 0.5987,
      "step": 235
    },
    {
      "epoch": 0.27602070155261643,
      "grad_norm": 6.579522132873535,
      "learning_rate": 2.9409094459800014e-05,
      "loss": 0.5503,
      "step": 240
    },
    {
      "epoch": 0.28177113283496263,
      "grad_norm": 5.339841842651367,
      "learning_rate": 2.9368781083898292e-05,
      "loss": 0.7425,
      "step": 245
    },
    {
      "epoch": 0.2875215641173088,
      "grad_norm": 4.521642684936523,
      "learning_rate": 2.9327167052562876e-05,
      "loss": 0.7633,
      "step": 250
    },
    {
      "epoch": 0.293271995399655,
      "grad_norm": 5.244660377502441,
      "learning_rate": 2.9284256132676676e-05,
      "loss": 0.6769,
      "step": 255
    },
    {
      "epoch": 0.29902242668200113,
      "grad_norm": 5.805805206298828,
      "learning_rate": 2.9240052208516364e-05,
      "loss": 0.6589,
      "step": 260
    },
    {
      "epoch": 0.30477285796434733,
      "grad_norm": 5.311351299285889,
      "learning_rate": 2.9194559281400762e-05,
      "loss": 0.7937,
      "step": 265
    },
    {
      "epoch": 0.3105232892466935,
      "grad_norm": 4.528520107269287,
      "learning_rate": 2.9147781469328637e-05,
      "loss": 0.7423,
      "step": 270
    },
    {
      "epoch": 0.3162737205290397,
      "grad_norm": 7.060060024261475,
      "learning_rate": 2.909972300660595e-05,
      "loss": 0.5863,
      "step": 275
    },
    {
      "epoch": 0.32202415181138583,
      "grad_norm": 6.4272871017456055,
      "learning_rate": 2.905038824346258e-05,
      "loss": 0.6132,
      "step": 280
    },
    {
      "epoch": 0.32777458309373203,
      "grad_norm": 6.567342758178711,
      "learning_rate": 2.899978164565852e-05,
      "loss": 0.6825,
      "step": 285
    },
    {
      "epoch": 0.33352501437607823,
      "grad_norm": 5.250909805297852,
      "learning_rate": 2.8947907794079646e-05,
      "loss": 0.6994,
      "step": 290
    },
    {
      "epoch": 0.3392754456584244,
      "grad_norm": 4.512757778167725,
      "learning_rate": 2.889477138432308e-05,
      "loss": 0.6021,
      "step": 295
    },
    {
      "epoch": 0.3450258769407706,
      "grad_norm": 3.319274663925171,
      "learning_rate": 2.8840377226272102e-05,
      "loss": 0.5842,
      "step": 300
    },
    {
      "epoch": 0.35077630822311673,
      "grad_norm": 5.050398826599121,
      "learning_rate": 2.8784730243660806e-05,
      "loss": 0.5726,
      "step": 305
    },
    {
      "epoch": 0.35652673950546293,
      "grad_norm": 4.035017013549805,
      "learning_rate": 2.872783547362838e-05,
      "loss": 0.7507,
      "step": 310
    },
    {
      "epoch": 0.3622771707878091,
      "grad_norm": 2.637155771255493,
      "learning_rate": 2.8669698066263163e-05,
      "loss": 0.5386,
      "step": 315
    },
    {
      "epoch": 0.3680276020701553,
      "grad_norm": 2.54348087310791,
      "learning_rate": 2.8610323284136432e-05,
      "loss": 0.5723,
      "step": 320
    },
    {
      "epoch": 0.3737780333525014,
      "grad_norm": 5.185069561004639,
      "learning_rate": 2.8549716501826075e-05,
      "loss": 0.7174,
      "step": 325
    },
    {
      "epoch": 0.37952846463484763,
      "grad_norm": 6.023434638977051,
      "learning_rate": 2.848788320543006e-05,
      "loss": 0.7375,
      "step": 330
    },
    {
      "epoch": 0.3852788959171938,
      "grad_norm": 3.6643548011779785,
      "learning_rate": 2.8424828992069846e-05,
      "loss": 0.5534,
      "step": 335
    },
    {
      "epoch": 0.39102932719954,
      "grad_norm": 3.97648024559021,
      "learning_rate": 2.8360559569383735e-05,
      "loss": 1.4471,
      "step": 340
    },
    {
      "epoch": 0.3967797584818861,
      "grad_norm": 4.666309833526611,
      "learning_rate": 2.829508075501021e-05,
      "loss": 0.7019,
      "step": 345
    },
    {
      "epoch": 0.4025301897642323,
      "grad_norm": 5.974145412445068,
      "learning_rate": 2.822839847606133e-05,
      "loss": 0.7438,
      "step": 350
    },
    {
      "epoch": 0.4082806210465785,
      "grad_norm": 4.68729305267334,
      "learning_rate": 2.816051876858623e-05,
      "loss": 0.6426,
      "step": 355
    },
    {
      "epoch": 0.4140310523289247,
      "grad_norm": 4.74967622756958,
      "learning_rate": 2.8091447777024697e-05,
      "loss": 0.6015,
      "step": 360
    },
    {
      "epoch": 0.4197814836112708,
      "grad_norm": 3.754143238067627,
      "learning_rate": 2.8021191753651025e-05,
      "loss": 0.7258,
      "step": 365
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 4.212744235992432,
      "learning_rate": 2.794975705800803e-05,
      "loss": 1.0033,
      "step": 370
    },
    {
      "epoch": 0.43128234617596317,
      "grad_norm": 4.979032039642334,
      "learning_rate": 2.7877150156331397e-05,
      "loss": 0.685,
      "step": 375
    },
    {
      "epoch": 0.4370327774583094,
      "grad_norm": 6.131329536437988,
      "learning_rate": 2.780337762096437e-05,
      "loss": 0.7587,
      "step": 380
    },
    {
      "epoch": 0.4427832087406556,
      "grad_norm": 3.494274616241455,
      "learning_rate": 2.7728446129762804e-05,
      "loss": 1.2777,
      "step": 385
    },
    {
      "epoch": 0.4485336400230017,
      "grad_norm": 2.417489528656006,
      "learning_rate": 2.7652362465490713e-05,
      "loss": 0.6535,
      "step": 390
    },
    {
      "epoch": 0.4542840713053479,
      "grad_norm": 4.654455184936523,
      "learning_rate": 2.7575133515206272e-05,
      "loss": 0.7386,
      "step": 395
    },
    {
      "epoch": 0.46003450258769407,
      "grad_norm": 5.411613941192627,
      "learning_rate": 2.749676626963844e-05,
      "loss": 0.5504,
      "step": 400
    },
    {
      "epoch": 0.4657849338700403,
      "grad_norm": 3.8645777702331543,
      "learning_rate": 2.7417267822554114e-05,
      "loss": 0.6539,
      "step": 405
    },
    {
      "epoch": 0.4715353651523864,
      "grad_norm": 5.198256015777588,
      "learning_rate": 2.7336645370116042e-05,
      "loss": 0.6726,
      "step": 410
    },
    {
      "epoch": 0.4772857964347326,
      "grad_norm": 4.88352632522583,
      "learning_rate": 2.7254906210231425e-05,
      "loss": 0.668,
      "step": 415
    },
    {
      "epoch": 0.48303622771707877,
      "grad_norm": 5.111018180847168,
      "learning_rate": 2.7172057741891296e-05,
      "loss": 0.6577,
      "step": 420
    },
    {
      "epoch": 0.48878665899942497,
      "grad_norm": 3.8200302124023438,
      "learning_rate": 2.7088107464500784e-05,
      "loss": 0.528,
      "step": 425
    },
    {
      "epoch": 0.4945370902817711,
      "grad_norm": 4.419477462768555,
      "learning_rate": 2.700306297720026e-05,
      "loss": 0.7305,
      "step": 430
    },
    {
      "epoch": 0.5002875215641173,
      "grad_norm": 5.100160121917725,
      "learning_rate": 2.6916931978177467e-05,
      "loss": 0.6143,
      "step": 435
    },
    {
      "epoch": 0.5060379528464635,
      "grad_norm": 4.0324249267578125,
      "learning_rate": 2.6829722263970708e-05,
      "loss": 0.6604,
      "step": 440
    },
    {
      "epoch": 0.5117883841288097,
      "grad_norm": 2.2977194786071777,
      "learning_rate": 2.674144172876306e-05,
      "loss": 0.5553,
      "step": 445
    },
    {
      "epoch": 0.5175388154111559,
      "grad_norm": 4.105257511138916,
      "learning_rate": 2.665209836366784e-05,
      "loss": 1.5079,
      "step": 450
    },
    {
      "epoch": 0.523289246693502,
      "grad_norm": 7.196156978607178,
      "learning_rate": 2.6561700256005243e-05,
      "loss": 0.6257,
      "step": 455
    },
    {
      "epoch": 0.5290396779758482,
      "grad_norm": 2.849140167236328,
      "learning_rate": 2.6470255588570242e-05,
      "loss": 0.5951,
      "step": 460
    },
    {
      "epoch": 0.5347901092581944,
      "grad_norm": 2.327407121658325,
      "learning_rate": 2.637777263889195e-05,
      "loss": 0.6874,
      "step": 465
    },
    {
      "epoch": 0.5405405405405406,
      "grad_norm": 2.5727458000183105,
      "learning_rate": 2.628425977848431e-05,
      "loss": 0.7412,
      "step": 470
    },
    {
      "epoch": 0.5462909718228867,
      "grad_norm": 3.4438962936401367,
      "learning_rate": 2.6189725472088276e-05,
      "loss": 0.6647,
      "step": 475
    },
    {
      "epoch": 0.5520414031052329,
      "grad_norm": 6.218929767608643,
      "learning_rate": 2.6094178276905656e-05,
      "loss": 0.7282,
      "step": 480
    },
    {
      "epoch": 0.5577918343875791,
      "grad_norm": 2.0243589878082275,
      "learning_rate": 2.5997626841824468e-05,
      "loss": 0.6545,
      "step": 485
    },
    {
      "epoch": 0.5635422656699253,
      "grad_norm": 3.3051552772521973,
      "learning_rate": 2.5900079906636063e-05,
      "loss": 0.6189,
      "step": 490
    },
    {
      "epoch": 0.5692926969522715,
      "grad_norm": 2.34004282951355,
      "learning_rate": 2.5801546301244004e-05,
      "loss": 0.6362,
      "step": 495
    },
    {
      "epoch": 0.5750431282346176,
      "grad_norm": 2.672454595565796,
      "learning_rate": 2.5702034944864797e-05,
      "loss": 0.6299,
      "step": 500
    },
    {
      "epoch": 0.5750431282346176,
      "eval_loss": 0.6521967649459839,
      "eval_runtime": 173.262,
      "eval_samples_per_second": 2.234,
      "eval_steps_per_second": 2.234,
      "step": 500
    },
    {
      "epoch": 0.5807935595169638,
      "grad_norm": 6.069749355316162,
      "learning_rate": 2.5601554845220493e-05,
      "loss": 0.7014,
      "step": 505
    },
    {
      "epoch": 0.58654399079931,
      "grad_norm": 3.4122636318206787,
      "learning_rate": 2.5500115097723348e-05,
      "loss": 0.6182,
      "step": 510
    },
    {
      "epoch": 0.5922944220816562,
      "grad_norm": 4.097920894622803,
      "learning_rate": 2.5397724884652504e-05,
      "loss": 0.7115,
      "step": 515
    },
    {
      "epoch": 0.5980448533640023,
      "grad_norm": 5.152074813842773,
      "learning_rate": 2.5294393474322805e-05,
      "loss": 0.7008,
      "step": 520
    },
    {
      "epoch": 0.6037952846463485,
      "grad_norm": 4.635739803314209,
      "learning_rate": 2.519013022024583e-05,
      "loss": 0.6792,
      "step": 525
    },
    {
      "epoch": 0.6095457159286947,
      "grad_norm": 2.2789790630340576,
      "learning_rate": 2.508494456028323e-05,
      "loss": 0.581,
      "step": 530
    },
    {
      "epoch": 0.6152961472110409,
      "grad_norm": 3.0844762325286865,
      "learning_rate": 2.4978846015792416e-05,
      "loss": 0.586,
      "step": 535
    },
    {
      "epoch": 0.621046578493387,
      "grad_norm": 3.2845401763916016,
      "learning_rate": 2.487184419076467e-05,
      "loss": 0.6068,
      "step": 540
    },
    {
      "epoch": 0.6267970097757332,
      "grad_norm": 3.8507301807403564,
      "learning_rate": 2.476394877095583e-05,
      "loss": 0.7106,
      "step": 545
    },
    {
      "epoch": 0.6325474410580794,
      "grad_norm": 3.4146335124969482,
      "learning_rate": 2.4655169523009505e-05,
      "loss": 1.1416,
      "step": 550
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 5.581892013549805,
      "learning_rate": 2.454551629357303e-05,
      "loss": 0.6192,
      "step": 555
    },
    {
      "epoch": 0.6440483036227717,
      "grad_norm": 2.8682329654693604,
      "learning_rate": 2.443499900840614e-05,
      "loss": 0.9819,
      "step": 560
    },
    {
      "epoch": 0.6497987349051179,
      "grad_norm": 3.169144630432129,
      "learning_rate": 2.4323627671482488e-05,
      "loss": 0.7304,
      "step": 565
    },
    {
      "epoch": 0.6555491661874641,
      "grad_norm": 3.428253412246704,
      "learning_rate": 2.4211412364084105e-05,
      "loss": 0.4939,
      "step": 570
    },
    {
      "epoch": 0.6612995974698103,
      "grad_norm": 2.223688840866089,
      "learning_rate": 2.4098363243888844e-05,
      "loss": 0.6891,
      "step": 575
    },
    {
      "epoch": 0.6670500287521565,
      "grad_norm": 3.9381728172302246,
      "learning_rate": 2.3984490544050895e-05,
      "loss": 0.7244,
      "step": 580
    },
    {
      "epoch": 0.6728004600345026,
      "grad_norm": 4.213131427764893,
      "learning_rate": 2.3869804572274508e-05,
      "loss": 0.5738,
      "step": 585
    },
    {
      "epoch": 0.6785508913168488,
      "grad_norm": 4.432726860046387,
      "learning_rate": 2.3754315709880934e-05,
      "loss": 0.7398,
      "step": 590
    },
    {
      "epoch": 0.684301322599195,
      "grad_norm": 1.8240488767623901,
      "learning_rate": 2.3638034410868696e-05,
      "loss": 0.7057,
      "step": 595
    },
    {
      "epoch": 0.6900517538815412,
      "grad_norm": 2.178314208984375,
      "learning_rate": 2.3520971200967337e-05,
      "loss": 0.6624,
      "step": 600
    },
    {
      "epoch": 0.6958021851638873,
      "grad_norm": 4.216614723205566,
      "learning_rate": 2.3403136676684598e-05,
      "loss": 0.6343,
      "step": 605
    },
    {
      "epoch": 0.7015526164462335,
      "grad_norm": 2.935086965560913,
      "learning_rate": 2.3284541504347248e-05,
      "loss": 0.6481,
      "step": 610
    },
    {
      "epoch": 0.7073030477285797,
      "grad_norm": 3.3354339599609375,
      "learning_rate": 2.3165196419135564e-05,
      "loss": 0.4767,
      "step": 615
    },
    {
      "epoch": 0.7130534790109259,
      "grad_norm": 3.666057825088501,
      "learning_rate": 2.3045112224111592e-05,
      "loss": 0.6023,
      "step": 620
    },
    {
      "epoch": 0.718803910293272,
      "grad_norm": 5.637306213378906,
      "learning_rate": 2.2924299789241255e-05,
      "loss": 0.6946,
      "step": 625
    },
    {
      "epoch": 0.7245543415756182,
      "grad_norm": 2.1937568187713623,
      "learning_rate": 2.280277005041041e-05,
      "loss": 0.6632,
      "step": 630
    },
    {
      "epoch": 0.7303047728579644,
      "grad_norm": 1.880415916442871,
      "learning_rate": 2.268053400843495e-05,
      "loss": 0.5638,
      "step": 635
    },
    {
      "epoch": 0.7360552041403106,
      "grad_norm": 3.8781933784484863,
      "learning_rate": 2.2557602728064982e-05,
      "loss": 0.5594,
      "step": 640
    },
    {
      "epoch": 0.7418056354226567,
      "grad_norm": 3.5550408363342285,
      "learning_rate": 2.2433987336983286e-05,
      "loss": 0.9841,
      "step": 645
    },
    {
      "epoch": 0.7475560667050029,
      "grad_norm": 4.056007385253906,
      "learning_rate": 2.2309699024798026e-05,
      "loss": 0.6299,
      "step": 650
    },
    {
      "epoch": 0.753306497987349,
      "grad_norm": 2.5823137760162354,
      "learning_rate": 2.218474904202987e-05,
      "loss": 0.6394,
      "step": 655
    },
    {
      "epoch": 0.7590569292696953,
      "grad_norm": 2.6700801849365234,
      "learning_rate": 2.20591486990936e-05,
      "loss": 0.6572,
      "step": 660
    },
    {
      "epoch": 0.7648073605520413,
      "grad_norm": 3.390245199203491,
      "learning_rate": 2.1932909365274315e-05,
      "loss": 0.6841,
      "step": 665
    },
    {
      "epoch": 0.7705577918343876,
      "grad_norm": 3.247098922729492,
      "learning_rate": 2.1806042467698253e-05,
      "loss": 0.5911,
      "step": 670
    },
    {
      "epoch": 0.7763082231167338,
      "grad_norm": 1.5109361410140991,
      "learning_rate": 2.167855949029845e-05,
      "loss": 0.6735,
      "step": 675
    },
    {
      "epoch": 0.78205865439908,
      "grad_norm": 2.585132598876953,
      "learning_rate": 2.1550471972775195e-05,
      "loss": 0.7159,
      "step": 680
    },
    {
      "epoch": 0.7878090856814262,
      "grad_norm": 2.5217134952545166,
      "learning_rate": 2.142179150955147e-05,
      "loss": 0.5298,
      "step": 685
    },
    {
      "epoch": 0.7935595169637722,
      "grad_norm": 3.4295153617858887,
      "learning_rate": 2.1292529748723436e-05,
      "loss": 0.5347,
      "step": 690
    },
    {
      "epoch": 0.7993099482461185,
      "grad_norm": 3.2724971771240234,
      "learning_rate": 2.1162698391006036e-05,
      "loss": 0.6361,
      "step": 695
    },
    {
      "epoch": 0.8050603795284647,
      "grad_norm": 3.7713980674743652,
      "learning_rate": 2.103230918867386e-05,
      "loss": 0.6754,
      "step": 700
    },
    {
      "epoch": 0.8108108108108109,
      "grad_norm": 2.151132345199585,
      "learning_rate": 2.0901373944497348e-05,
      "loss": 0.6491,
      "step": 705
    },
    {
      "epoch": 0.816561242093157,
      "grad_norm": 5.405221939086914,
      "learning_rate": 2.0769904510674382e-05,
      "loss": 0.6522,
      "step": 710
    },
    {
      "epoch": 0.8223116733755031,
      "grad_norm": 3.221045732498169,
      "learning_rate": 2.0637912787757447e-05,
      "loss": 0.552,
      "step": 715
    },
    {
      "epoch": 0.8280621046578494,
      "grad_norm": 2.8791940212249756,
      "learning_rate": 2.0505410723576404e-05,
      "loss": 0.6298,
      "step": 720
    },
    {
      "epoch": 0.8338125359401956,
      "grad_norm": 3.475503444671631,
      "learning_rate": 2.037241031215696e-05,
      "loss": 0.6889,
      "step": 725
    },
    {
      "epoch": 0.8395629672225416,
      "grad_norm": 3.2935500144958496,
      "learning_rate": 2.0238923592634984e-05,
      "loss": 0.6003,
      "step": 730
    },
    {
      "epoch": 0.8453133985048878,
      "grad_norm": 5.344400405883789,
      "learning_rate": 2.010496264816674e-05,
      "loss": 0.6429,
      "step": 735
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 3.500089406967163,
      "learning_rate": 1.9970539604835112e-05,
      "loss": 0.6883,
      "step": 740
    },
    {
      "epoch": 0.8568142610695803,
      "grad_norm": 2.85532808303833,
      "learning_rate": 1.9835666630551947e-05,
      "loss": 0.6464,
      "step": 745
    },
    {
      "epoch": 0.8625646923519263,
      "grad_norm": 3.1056456565856934,
      "learning_rate": 1.970035593395665e-05,
      "loss": 0.7497,
      "step": 750
    },
    {
      "epoch": 0.8683151236342725,
      "grad_norm": 2.92326283454895,
      "learning_rate": 1.9564619763311043e-05,
      "loss": 0.6389,
      "step": 755
    },
    {
      "epoch": 0.8740655549166187,
      "grad_norm": 4.086975574493408,
      "learning_rate": 1.942847040539066e-05,
      "loss": 0.6347,
      "step": 760
    },
    {
      "epoch": 0.879815986198965,
      "grad_norm": 3.3999743461608887,
      "learning_rate": 1.929192018437256e-05,
      "loss": 0.6151,
      "step": 765
    },
    {
      "epoch": 0.8855664174813112,
      "grad_norm": 3.0688488483428955,
      "learning_rate": 1.9154981460719743e-05,
      "loss": 0.6027,
      "step": 770
    },
    {
      "epoch": 0.8913168487636572,
      "grad_norm": 2.7920870780944824,
      "learning_rate": 1.9017666630062283e-05,
      "loss": 0.6307,
      "step": 775
    },
    {
      "epoch": 0.8970672800460034,
      "grad_norm": 4.370265483856201,
      "learning_rate": 1.8879988122075296e-05,
      "loss": 0.5867,
      "step": 780
    },
    {
      "epoch": 0.9028177113283496,
      "grad_norm": 3.592892646789551,
      "learning_rate": 1.8741958399353794e-05,
      "loss": 0.7005,
      "step": 785
    },
    {
      "epoch": 0.9085681426106959,
      "grad_norm": 2.3805699348449707,
      "learning_rate": 1.8603589956284594e-05,
      "loss": 0.5617,
      "step": 790
    },
    {
      "epoch": 0.9143185738930419,
      "grad_norm": 4.261192321777344,
      "learning_rate": 1.8464895317915314e-05,
      "loss": 0.6201,
      "step": 795
    },
    {
      "epoch": 0.9200690051753881,
      "grad_norm": 3.3648269176483154,
      "learning_rate": 1.8325887038820616e-05,
      "loss": 0.63,
      "step": 800
    },
    {
      "epoch": 0.9258194364577343,
      "grad_norm": 1.5335795879364014,
      "learning_rate": 1.81865777019658e-05,
      "loss": 0.5706,
      "step": 805
    },
    {
      "epoch": 0.9315698677400805,
      "grad_norm": 2.8629724979400635,
      "learning_rate": 1.804697991756774e-05,
      "loss": 0.6407,
      "step": 810
    },
    {
      "epoch": 0.9373202990224266,
      "grad_norm": 2.9412920475006104,
      "learning_rate": 1.7907106321953472e-05,
      "loss": 0.5706,
      "step": 815
    },
    {
      "epoch": 0.9430707303047728,
      "grad_norm": 3.9021689891815186,
      "learning_rate": 1.776696957641634e-05,
      "loss": 0.6265,
      "step": 820
    },
    {
      "epoch": 0.948821161587119,
      "grad_norm": 3.4475302696228027,
      "learning_rate": 1.7626582366069878e-05,
      "loss": 0.6475,
      "step": 825
    },
    {
      "epoch": 0.9545715928694652,
      "grad_norm": 3.3524200916290283,
      "learning_rate": 1.748595739869959e-05,
      "loss": 0.6445,
      "step": 830
    },
    {
      "epoch": 0.9603220241518113,
      "grad_norm": 3.9803669452667236,
      "learning_rate": 1.7345107403612646e-05,
      "loss": 0.6138,
      "step": 835
    },
    {
      "epoch": 0.9660724554341575,
      "grad_norm": 2.6932716369628906,
      "learning_rate": 1.7204045130485598e-05,
      "loss": 0.5762,
      "step": 840
    },
    {
      "epoch": 0.9718228867165037,
      "grad_norm": 2.421907901763916,
      "learning_rate": 1.706278334821032e-05,
      "loss": 0.5497,
      "step": 845
    },
    {
      "epoch": 0.9775733179988499,
      "grad_norm": 2.5507733821868896,
      "learning_rate": 1.6921334843738175e-05,
      "loss": 0.6263,
      "step": 850
    },
    {
      "epoch": 0.983323749281196,
      "grad_norm": 3.5708305835723877,
      "learning_rate": 1.6779712420922517e-05,
      "loss": 0.5903,
      "step": 855
    },
    {
      "epoch": 0.9890741805635422,
      "grad_norm": 3.392023801803589,
      "learning_rate": 1.6637928899359697e-05,
      "loss": 0.612,
      "step": 860
    },
    {
      "epoch": 0.9948246118458884,
      "grad_norm": 3.9513823986053467,
      "learning_rate": 1.6495997113228685e-05,
      "loss": 0.7113,
      "step": 865
    },
    {
      "epoch": 1.0005750431282345,
      "grad_norm": 6.166500091552734,
      "learning_rate": 1.6353929910129267e-05,
      "loss": 0.6696,
      "step": 870
    },
    {
      "epoch": 1.0063254744105807,
      "grad_norm": 2.76430606842041,
      "learning_rate": 1.6211740149919108e-05,
      "loss": 0.6455,
      "step": 875
    },
    {
      "epoch": 1.012075905692927,
      "grad_norm": 1.9572592973709106,
      "learning_rate": 1.6069440703549698e-05,
      "loss": 0.5984,
      "step": 880
    },
    {
      "epoch": 1.0178263369752731,
      "grad_norm": 2.8748841285705566,
      "learning_rate": 1.5927044451901265e-05,
      "loss": 0.6675,
      "step": 885
    },
    {
      "epoch": 1.0235767682576193,
      "grad_norm": 2.7764170169830322,
      "learning_rate": 1.5784564284616795e-05,
      "loss": 0.5828,
      "step": 890
    },
    {
      "epoch": 1.0293271995399655,
      "grad_norm": 3.025813579559326,
      "learning_rate": 1.56420130989353e-05,
      "loss": 0.5676,
      "step": 895
    },
    {
      "epoch": 1.0350776308223117,
      "grad_norm": 3.313161611557007,
      "learning_rate": 1.5499403798524327e-05,
      "loss": 0.5866,
      "step": 900
    },
    {
      "epoch": 1.040828062104658,
      "grad_norm": 3.4412403106689453,
      "learning_rate": 1.5356749292311933e-05,
      "loss": 0.5519,
      "step": 905
    },
    {
      "epoch": 1.046578493387004,
      "grad_norm": 3.49349308013916,
      "learning_rate": 1.5214062493318224e-05,
      "loss": 0.5427,
      "step": 910
    },
    {
      "epoch": 1.0523289246693501,
      "grad_norm": 7.519076347351074,
      "learning_rate": 1.507135631748639e-05,
      "loss": 0.7091,
      "step": 915
    },
    {
      "epoch": 1.0580793559516963,
      "grad_norm": 3.6433374881744385,
      "learning_rate": 1.4928643682513617e-05,
      "loss": 0.6585,
      "step": 920
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 2.9976274967193604,
      "learning_rate": 1.4785937506681778e-05,
      "loss": 0.5612,
      "step": 925
    },
    {
      "epoch": 1.0695802185163887,
      "grad_norm": 2.969806671142578,
      "learning_rate": 1.4643250707688063e-05,
      "loss": 0.5109,
      "step": 930
    },
    {
      "epoch": 1.075330649798735,
      "grad_norm": 2.8926076889038086,
      "learning_rate": 1.450059620147568e-05,
      "loss": 0.5228,
      "step": 935
    },
    {
      "epoch": 1.0810810810810811,
      "grad_norm": 3.554243803024292,
      "learning_rate": 1.4357986901064703e-05,
      "loss": 0.6101,
      "step": 940
    },
    {
      "epoch": 1.0868315123634273,
      "grad_norm": 2.4129748344421387,
      "learning_rate": 1.4215435715383206e-05,
      "loss": 1.379,
      "step": 945
    },
    {
      "epoch": 1.0925819436457735,
      "grad_norm": 4.244594573974609,
      "learning_rate": 1.4072955548098741e-05,
      "loss": 0.5913,
      "step": 950
    },
    {
      "epoch": 1.0983323749281195,
      "grad_norm": 5.154474258422852,
      "learning_rate": 1.3930559296450305e-05,
      "loss": 0.6392,
      "step": 955
    },
    {
      "epoch": 1.1040828062104657,
      "grad_norm": 4.411839485168457,
      "learning_rate": 1.3788259850080893e-05,
      "loss": 0.6303,
      "step": 960
    },
    {
      "epoch": 1.109833237492812,
      "grad_norm": 5.069469928741455,
      "learning_rate": 1.3646070089870737e-05,
      "loss": 0.7842,
      "step": 965
    },
    {
      "epoch": 1.1155836687751581,
      "grad_norm": 2.6116108894348145,
      "learning_rate": 1.3504002886771315e-05,
      "loss": 0.6201,
      "step": 970
    },
    {
      "epoch": 1.1213341000575043,
      "grad_norm": 3.5151872634887695,
      "learning_rate": 1.3362071100640302e-05,
      "loss": 0.5459,
      "step": 975
    },
    {
      "epoch": 1.1270845313398505,
      "grad_norm": 2.7099342346191406,
      "learning_rate": 1.3220287579077492e-05,
      "loss": 0.4588,
      "step": 980
    },
    {
      "epoch": 1.1328349626221967,
      "grad_norm": 4.109795570373535,
      "learning_rate": 1.3078665156261827e-05,
      "loss": 0.6556,
      "step": 985
    },
    {
      "epoch": 1.1385853939045427,
      "grad_norm": 4.26898193359375,
      "learning_rate": 1.293721665178968e-05,
      "loss": 0.5505,
      "step": 990
    },
    {
      "epoch": 1.144335825186889,
      "grad_norm": 2.7798080444335938,
      "learning_rate": 1.2795954869514408e-05,
      "loss": 0.5926,
      "step": 995
    },
    {
      "epoch": 1.1500862564692351,
      "grad_norm": 4.51052188873291,
      "learning_rate": 1.2654892596387358e-05,
      "loss": 0.6191,
      "step": 1000
    },
    {
      "epoch": 1.1500862564692351,
      "eval_loss": 0.657077968120575,
      "eval_runtime": 183.3832,
      "eval_samples_per_second": 2.11,
      "eval_steps_per_second": 2.11,
      "step": 1000
    },
    {
      "epoch": 1.1558366877515813,
      "grad_norm": 3.791532278060913,
      "learning_rate": 1.2514042601300408e-05,
      "loss": 0.6754,
      "step": 1005
    },
    {
      "epoch": 1.1615871190339275,
      "grad_norm": 1.8289302587509155,
      "learning_rate": 1.2373417633930126e-05,
      "loss": 0.5169,
      "step": 1010
    },
    {
      "epoch": 1.1673375503162737,
      "grad_norm": 3.450920820236206,
      "learning_rate": 1.2233030423583662e-05,
      "loss": 0.4341,
      "step": 1015
    },
    {
      "epoch": 1.17308798159862,
      "grad_norm": 3.414832830429077,
      "learning_rate": 1.2092893678046527e-05,
      "loss": 0.6292,
      "step": 1020
    },
    {
      "epoch": 1.1788384128809661,
      "grad_norm": 2.849924325942993,
      "learning_rate": 1.1953020082432264e-05,
      "loss": 0.5895,
      "step": 1025
    },
    {
      "epoch": 1.1845888441633123,
      "grad_norm": 3.009108781814575,
      "learning_rate": 1.1813422298034207e-05,
      "loss": 0.4638,
      "step": 1030
    },
    {
      "epoch": 1.1903392754456585,
      "grad_norm": 5.706718921661377,
      "learning_rate": 1.1674112961179383e-05,
      "loss": 0.6509,
      "step": 1035
    },
    {
      "epoch": 1.1960897067280045,
      "grad_norm": 3.604215383529663,
      "learning_rate": 1.1535104682084692e-05,
      "loss": 0.5369,
      "step": 1040
    },
    {
      "epoch": 1.2018401380103507,
      "grad_norm": 2.6761040687561035,
      "learning_rate": 1.139641004371541e-05,
      "loss": 0.5656,
      "step": 1045
    },
    {
      "epoch": 1.207590569292697,
      "grad_norm": 3.509829044342041,
      "learning_rate": 1.1258041600646208e-05,
      "loss": 0.5844,
      "step": 1050
    },
    {
      "epoch": 1.2133410005750431,
      "grad_norm": 4.641816139221191,
      "learning_rate": 1.112001187792471e-05,
      "loss": 0.6161,
      "step": 1055
    },
    {
      "epoch": 1.2190914318573893,
      "grad_norm": 3.347876787185669,
      "learning_rate": 1.0982333369937721e-05,
      "loss": 0.5799,
      "step": 1060
    },
    {
      "epoch": 1.2248418631397355,
      "grad_norm": 3.1021201610565186,
      "learning_rate": 1.0845018539280261e-05,
      "loss": 0.7739,
      "step": 1065
    },
    {
      "epoch": 1.2305922944220817,
      "grad_norm": 2.7590067386627197,
      "learning_rate": 1.0708079815627443e-05,
      "loss": 0.4943,
      "step": 1070
    },
    {
      "epoch": 1.2363427257044277,
      "grad_norm": 3.0395302772521973,
      "learning_rate": 1.0571529594609341e-05,
      "loss": 0.5155,
      "step": 1075
    },
    {
      "epoch": 1.242093156986774,
      "grad_norm": 2.504845142364502,
      "learning_rate": 1.0435380236688958e-05,
      "loss": 0.6498,
      "step": 1080
    },
    {
      "epoch": 1.2478435882691201,
      "grad_norm": 7.176849842071533,
      "learning_rate": 1.0299644066043353e-05,
      "loss": 0.6238,
      "step": 1085
    },
    {
      "epoch": 1.2535940195514663,
      "grad_norm": 3.5495479106903076,
      "learning_rate": 1.0164333369448057e-05,
      "loss": 0.5913,
      "step": 1090
    },
    {
      "epoch": 1.2593444508338125,
      "grad_norm": 2.793959140777588,
      "learning_rate": 1.0029460395164893e-05,
      "loss": 0.5436,
      "step": 1095
    },
    {
      "epoch": 1.2650948821161587,
      "grad_norm": 3.268993377685547,
      "learning_rate": 9.895037351833263e-06,
      "loss": 0.6329,
      "step": 1100
    },
    {
      "epoch": 1.270845313398505,
      "grad_norm": 2.3793509006500244,
      "learning_rate": 9.761076407365019e-06,
      "loss": 0.7608,
      "step": 1105
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 2.355344533920288,
      "learning_rate": 9.627589687843045e-06,
      "loss": 0.5569,
      "step": 1110
    },
    {
      "epoch": 1.2823461759631973,
      "grad_norm": 2.6985278129577637,
      "learning_rate": 9.4945892764236e-06,
      "loss": 0.6102,
      "step": 1115
    },
    {
      "epoch": 1.2880966072455435,
      "grad_norm": 3.1216602325439453,
      "learning_rate": 9.362087212242554e-06,
      "loss": 0.5876,
      "step": 1120
    },
    {
      "epoch": 1.2938470385278895,
      "grad_norm": 4.463257312774658,
      "learning_rate": 9.230095489325619e-06,
      "loss": 0.5735,
      "step": 1125
    },
    {
      "epoch": 1.2995974698102357,
      "grad_norm": 5.010990619659424,
      "learning_rate": 9.098626055502655e-06,
      "loss": 0.6288,
      "step": 1130
    },
    {
      "epoch": 1.305347901092582,
      "grad_norm": 2.418525218963623,
      "learning_rate": 8.967690811326141e-06,
      "loss": 0.7326,
      "step": 1135
    },
    {
      "epoch": 1.3110983323749281,
      "grad_norm": 8.593329429626465,
      "learning_rate": 8.837301608993967e-06,
      "loss": 0.5763,
      "step": 1140
    },
    {
      "epoch": 1.3168487636572743,
      "grad_norm": 3.3870620727539062,
      "learning_rate": 8.707470251276568e-06,
      "loss": 0.6097,
      "step": 1145
    },
    {
      "epoch": 1.3225991949396205,
      "grad_norm": 5.9260358810424805,
      "learning_rate": 8.578208490448526e-06,
      "loss": 0.6182,
      "step": 1150
    },
    {
      "epoch": 1.3283496262219667,
      "grad_norm": 2.904026508331299,
      "learning_rate": 8.449528027224807e-06,
      "loss": 0.5998,
      "step": 1155
    },
    {
      "epoch": 1.3341000575043127,
      "grad_norm": 3.734711170196533,
      "learning_rate": 8.321440509701552e-06,
      "loss": 0.5859,
      "step": 1160
    },
    {
      "epoch": 1.339850488786659,
      "grad_norm": 3.389238119125366,
      "learning_rate": 8.193957532301746e-06,
      "loss": 0.6129,
      "step": 1165
    },
    {
      "epoch": 1.3456009200690051,
      "grad_norm": 2.282947301864624,
      "learning_rate": 8.067090634725686e-06,
      "loss": 0.6481,
      "step": 1170
    },
    {
      "epoch": 1.3513513513513513,
      "grad_norm": 2.231928586959839,
      "learning_rate": 7.940851300906401e-06,
      "loss": 0.5472,
      "step": 1175
    },
    {
      "epoch": 1.3571017826336975,
      "grad_norm": 2.7360260486602783,
      "learning_rate": 7.81525095797013e-06,
      "loss": 0.5613,
      "step": 1180
    },
    {
      "epoch": 1.3628522139160437,
      "grad_norm": 4.9032158851623535,
      "learning_rate": 7.690300975201976e-06,
      "loss": 0.5165,
      "step": 1185
    },
    {
      "epoch": 1.36860264519839,
      "grad_norm": 5.335206985473633,
      "learning_rate": 7.566012663016716e-06,
      "loss": 0.5757,
      "step": 1190
    },
    {
      "epoch": 1.3743530764807361,
      "grad_norm": 2.967599391937256,
      "learning_rate": 7.442397271935017e-06,
      "loss": 0.5477,
      "step": 1195
    },
    {
      "epoch": 1.3801035077630823,
      "grad_norm": 5.839829444885254,
      "learning_rate": 7.319465991565052e-06,
      "loss": 0.5718,
      "step": 1200
    },
    {
      "epoch": 1.3858539390454285,
      "grad_norm": 2.6245269775390625,
      "learning_rate": 7.1972299495895896e-06,
      "loss": 0.4101,
      "step": 1205
    },
    {
      "epoch": 1.3916043703277745,
      "grad_norm": 4.6904377937316895,
      "learning_rate": 7.075700210758744e-06,
      "loss": 0.5726,
      "step": 1210
    },
    {
      "epoch": 1.3973548016101207,
      "grad_norm": 2.2274866104125977,
      "learning_rate": 6.954887775888413e-06,
      "loss": 0.565,
      "step": 1215
    },
    {
      "epoch": 1.403105232892467,
      "grad_norm": 2.5411996841430664,
      "learning_rate": 6.834803580864437e-06,
      "loss": 0.547,
      "step": 1220
    },
    {
      "epoch": 1.4088556641748131,
      "grad_norm": 3.326536178588867,
      "learning_rate": 6.715458495652749e-06,
      "loss": 0.614,
      "step": 1225
    },
    {
      "epoch": 1.4146060954571593,
      "grad_norm": 2.583275556564331,
      "learning_rate": 6.596863323315407e-06,
      "loss": 0.5757,
      "step": 1230
    },
    {
      "epoch": 1.4203565267395055,
      "grad_norm": 2.829892873764038,
      "learning_rate": 6.479028799032664e-06,
      "loss": 0.6262,
      "step": 1235
    },
    {
      "epoch": 1.4261069580218515,
      "grad_norm": 3.266226053237915,
      "learning_rate": 6.361965589131303e-06,
      "loss": 0.5336,
      "step": 1240
    },
    {
      "epoch": 1.4318573893041977,
      "grad_norm": 5.817966461181641,
      "learning_rate": 6.245684290119076e-06,
      "loss": 0.5532,
      "step": 1245
    },
    {
      "epoch": 1.437607820586544,
      "grad_norm": 2.1607706546783447,
      "learning_rate": 6.130195427725494e-06,
      "loss": 0.5483,
      "step": 1250
    },
    {
      "epoch": 1.44335825186889,
      "grad_norm": 3.54079532623291,
      "learning_rate": 6.0155094559491025e-06,
      "loss": 0.5227,
      "step": 1255
    },
    {
      "epoch": 1.4491086831512363,
      "grad_norm": 2.928656578063965,
      "learning_rate": 5.9016367561111615e-06,
      "loss": 0.6137,
      "step": 1260
    },
    {
      "epoch": 1.4548591144335825,
      "grad_norm": 4.057140827178955,
      "learning_rate": 5.788587635915896e-06,
      "loss": 0.6487,
      "step": 1265
    },
    {
      "epoch": 1.4606095457159287,
      "grad_norm": 3.5849993228912354,
      "learning_rate": 5.676372328517512e-06,
      "loss": 0.6329,
      "step": 1270
    },
    {
      "epoch": 1.466359976998275,
      "grad_norm": 3.540118932723999,
      "learning_rate": 5.5650009915938675e-06,
      "loss": 0.5836,
      "step": 1275
    },
    {
      "epoch": 1.4721104082806211,
      "grad_norm": 3.456296920776367,
      "learning_rate": 5.454483706426973e-06,
      "loss": 0.5495,
      "step": 1280
    },
    {
      "epoch": 1.4778608395629673,
      "grad_norm": 2.6592674255371094,
      "learning_rate": 5.344830476990496e-06,
      "loss": 0.5172,
      "step": 1285
    },
    {
      "epoch": 1.4836112708453135,
      "grad_norm": 3.6272501945495605,
      "learning_rate": 5.2360512290441784e-06,
      "loss": 0.6782,
      "step": 1290
    },
    {
      "epoch": 1.4893617021276595,
      "grad_norm": 2.0325512886047363,
      "learning_rate": 5.128155809235333e-06,
      "loss": 0.6673,
      "step": 1295
    },
    {
      "epoch": 1.4951121334100057,
      "grad_norm": 2.4630072116851807,
      "learning_rate": 5.021153984207587e-06,
      "loss": 0.4896,
      "step": 1300
    },
    {
      "epoch": 1.500862564692352,
      "grad_norm": 3.4507389068603516,
      "learning_rate": 4.9150554397167775e-06,
      "loss": 0.6261,
      "step": 1305
    },
    {
      "epoch": 1.506612995974698,
      "grad_norm": 3.5795726776123047,
      "learning_rate": 4.809869779754175e-06,
      "loss": 1.0246,
      "step": 1310
    },
    {
      "epoch": 1.5123634272570443,
      "grad_norm": 4.382437229156494,
      "learning_rate": 4.705606525677197e-06,
      "loss": 0.5642,
      "step": 1315
    },
    {
      "epoch": 1.5181138585393903,
      "grad_norm": 3.2202837467193604,
      "learning_rate": 4.6022751153475025e-06,
      "loss": 0.5745,
      "step": 1320
    },
    {
      "epoch": 1.5238642898217365,
      "grad_norm": 4.280174255371094,
      "learning_rate": 4.499884902276655e-06,
      "loss": 0.6157,
      "step": 1325
    },
    {
      "epoch": 1.5296147211040827,
      "grad_norm": 3.695253610610962,
      "learning_rate": 4.3984451547795085e-06,
      "loss": 0.569,
      "step": 1330
    },
    {
      "epoch": 1.535365152386429,
      "grad_norm": 3.84769344329834,
      "learning_rate": 4.2979650551352095e-06,
      "loss": 0.6772,
      "step": 1335
    },
    {
      "epoch": 1.541115583668775,
      "grad_norm": 5.645263671875,
      "learning_rate": 4.198453698755995e-06,
      "loss": 0.6185,
      "step": 1340
    },
    {
      "epoch": 1.5468660149511213,
      "grad_norm": 2.205178737640381,
      "learning_rate": 4.099920093363937e-06,
      "loss": 0.6247,
      "step": 1345
    },
    {
      "epoch": 1.5526164462334675,
      "grad_norm": 3.083732843399048,
      "learning_rate": 4.0023731581755385e-06,
      "loss": 0.4963,
      "step": 1350
    },
    {
      "epoch": 1.5583668775158137,
      "grad_norm": 3.020174264907837,
      "learning_rate": 3.9058217230943485e-06,
      "loss": 0.5122,
      "step": 1355
    },
    {
      "epoch": 1.56411730879816,
      "grad_norm": 5.237298965454102,
      "learning_rate": 3.8102745279117253e-06,
      "loss": 0.6149,
      "step": 1360
    },
    {
      "epoch": 1.5698677400805061,
      "grad_norm": 3.281101942062378,
      "learning_rate": 3.7157402215157e-06,
      "loss": 0.6269,
      "step": 1365
    },
    {
      "epoch": 1.5756181713628523,
      "grad_norm": 4.120241165161133,
      "learning_rate": 3.6222273611080482e-06,
      "loss": 0.5665,
      "step": 1370
    },
    {
      "epoch": 1.5813686026451985,
      "grad_norm": 3.438825845718384,
      "learning_rate": 3.529744411429758e-06,
      "loss": 0.5711,
      "step": 1375
    },
    {
      "epoch": 1.5871190339275447,
      "grad_norm": 3.95397686958313,
      "learning_rate": 3.4382997439947663e-06,
      "loss": 0.5531,
      "step": 1380
    },
    {
      "epoch": 1.5928694652098907,
      "grad_norm": 4.574751377105713,
      "learning_rate": 3.3479016363321603e-06,
      "loss": 0.5637,
      "step": 1385
    },
    {
      "epoch": 1.598619896492237,
      "grad_norm": 4.369913578033447,
      "learning_rate": 3.25855827123694e-06,
      "loss": 0.5521,
      "step": 1390
    },
    {
      "epoch": 1.604370327774583,
      "grad_norm": 2.6800999641418457,
      "learning_rate": 3.1702777360292956e-06,
      "loss": 0.5878,
      "step": 1395
    },
    {
      "epoch": 1.6101207590569293,
      "grad_norm": 5.950848579406738,
      "learning_rate": 3.0830680218225347e-06,
      "loss": 0.5773,
      "step": 1400
    },
    {
      "epoch": 1.6158711903392753,
      "grad_norm": 3.341139793395996,
      "learning_rate": 2.9969370227997434e-06,
      "loss": 0.5846,
      "step": 1405
    },
    {
      "epoch": 1.6216216216216215,
      "grad_norm": 2.3592171669006348,
      "learning_rate": 2.9118925354992177e-06,
      "loss": 0.694,
      "step": 1410
    },
    {
      "epoch": 1.6273720529039677,
      "grad_norm": 5.949657440185547,
      "learning_rate": 2.827942258108705e-06,
      "loss": 0.6919,
      "step": 1415
    },
    {
      "epoch": 1.633122484186314,
      "grad_norm": 3.5703482627868652,
      "learning_rate": 2.745093789768574e-06,
      "loss": 0.5591,
      "step": 1420
    },
    {
      "epoch": 1.63887291546866,
      "grad_norm": 2.8155276775360107,
      "learning_rate": 2.6633546298839583e-06,
      "loss": 0.5491,
      "step": 1425
    },
    {
      "epoch": 1.6446233467510063,
      "grad_norm": 4.409527778625488,
      "learning_rate": 2.5827321774458913e-06,
      "loss": 0.5673,
      "step": 1430
    },
    {
      "epoch": 1.6503737780333525,
      "grad_norm": 4.799320220947266,
      "learning_rate": 2.503233730361561e-06,
      "loss": 0.6225,
      "step": 1435
    },
    {
      "epoch": 1.6561242093156987,
      "grad_norm": 3.335658550262451,
      "learning_rate": 2.424866484793727e-06,
      "loss": 0.5497,
      "step": 1440
    },
    {
      "epoch": 1.661874640598045,
      "grad_norm": 3.6624033451080322,
      "learning_rate": 2.347637534509291e-06,
      "loss": 0.5758,
      "step": 1445
    },
    {
      "epoch": 1.667625071880391,
      "grad_norm": 3.1243703365325928,
      "learning_rate": 2.2715538702371956e-06,
      "loss": 0.6179,
      "step": 1450
    },
    {
      "epoch": 1.6733755031627373,
      "grad_norm": 3.372321367263794,
      "learning_rate": 2.1966223790356315e-06,
      "loss": 0.6104,
      "step": 1455
    },
    {
      "epoch": 1.6791259344450835,
      "grad_norm": 3.99330997467041,
      "learning_rate": 2.122849843668604e-06,
      "loss": 0.6004,
      "step": 1460
    },
    {
      "epoch": 1.6848763657274297,
      "grad_norm": 3.3178067207336426,
      "learning_rate": 2.0502429419919693e-06,
      "loss": 0.6444,
      "step": 1465
    },
    {
      "epoch": 1.6906267970097757,
      "grad_norm": 2.672297954559326,
      "learning_rate": 1.9788082463489743e-06,
      "loss": 0.4692,
      "step": 1470
    },
    {
      "epoch": 1.696377228292122,
      "grad_norm": 4.449657917022705,
      "learning_rate": 1.9085522229753037e-06,
      "loss": 0.4831,
      "step": 1475
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 2.745081663131714,
      "learning_rate": 1.8394812314137704e-06,
      "loss": 0.5636,
      "step": 1480
    },
    {
      "epoch": 1.7078780908568143,
      "grad_norm": 4.166896820068359,
      "learning_rate": 1.771601523938669e-06,
      "loss": 0.6975,
      "step": 1485
    },
    {
      "epoch": 1.7136285221391603,
      "grad_norm": 4.015562057495117,
      "learning_rate": 1.704919244989795e-06,
      "loss": 0.59,
      "step": 1490
    },
    {
      "epoch": 1.7193789534215065,
      "grad_norm": 2.710156202316284,
      "learning_rate": 1.639440430616267e-06,
      "loss": 0.5611,
      "step": 1495
    },
    {
      "epoch": 1.7251293847038527,
      "grad_norm": 3.8138318061828613,
      "learning_rate": 1.5751710079301546e-06,
      "loss": 0.4993,
      "step": 1500
    },
    {
      "epoch": 1.7251293847038527,
      "eval_loss": 0.625176727771759,
      "eval_runtime": 173.0373,
      "eval_samples_per_second": 2.237,
      "eval_steps_per_second": 2.237,
      "step": 1500
    },
    {
      "epoch": 1.7308798159861989,
      "grad_norm": 2.7341949939727783,
      "learning_rate": 1.512116794569942e-06,
      "loss": 0.5157,
      "step": 1505
    },
    {
      "epoch": 1.736630247268545,
      "grad_norm": 4.168917655944824,
      "learning_rate": 1.4502834981739265e-06,
      "loss": 0.6952,
      "step": 1510
    },
    {
      "epoch": 1.7423806785508913,
      "grad_norm": 4.910090923309326,
      "learning_rate": 1.3896767158635693e-06,
      "loss": 0.6475,
      "step": 1515
    },
    {
      "epoch": 1.7481311098332375,
      "grad_norm": 2.774700164794922,
      "learning_rate": 1.330301933736841e-06,
      "loss": 0.5154,
      "step": 1520
    },
    {
      "epoch": 1.7538815411155837,
      "grad_norm": 3.965400218963623,
      "learning_rate": 1.272164526371618e-06,
      "loss": 0.7334,
      "step": 1525
    },
    {
      "epoch": 1.75963197239793,
      "grad_norm": 2.4235079288482666,
      "learning_rate": 1.2152697563391956e-06,
      "loss": 0.5061,
      "step": 1530
    },
    {
      "epoch": 1.765382403680276,
      "grad_norm": 1.9765658378601074,
      "learning_rate": 1.1596227737279014e-06,
      "loss": 0.4954,
      "step": 1535
    },
    {
      "epoch": 1.7711328349626223,
      "grad_norm": 2.6061911582946777,
      "learning_rate": 1.1052286156769226e-06,
      "loss": 0.5331,
      "step": 1540
    },
    {
      "epoch": 1.7768832662449685,
      "grad_norm": 3.550187826156616,
      "learning_rate": 1.052092205920353e-06,
      "loss": 0.5656,
      "step": 1545
    },
    {
      "epoch": 1.7826336975273147,
      "grad_norm": 2.684680938720703,
      "learning_rate": 1.0002183543414829e-06,
      "loss": 0.6246,
      "step": 1550
    },
    {
      "epoch": 1.7883841288096607,
      "grad_norm": 4.951221942901611,
      "learning_rate": 9.496117565374196e-07,
      "loss": 0.6379,
      "step": 1555
    },
    {
      "epoch": 1.794134560092007,
      "grad_norm": 3.0435965061187744,
      "learning_rate": 9.002769933940491e-07,
      "loss": 0.4596,
      "step": 1560
    },
    {
      "epoch": 1.799884991374353,
      "grad_norm": 2.461885690689087,
      "learning_rate": 8.522185306713664e-07,
      "loss": 0.6101,
      "step": 1565
    },
    {
      "epoch": 1.8056354226566993,
      "grad_norm": 3.441535234451294,
      "learning_rate": 8.054407185992397e-07,
      "loss": 0.5495,
      "step": 1570
    },
    {
      "epoch": 1.8113858539390453,
      "grad_norm": 3.6067588329315186,
      "learning_rate": 7.599477914836362e-07,
      "loss": 0.5797,
      "step": 1575
    },
    {
      "epoch": 1.8171362852213915,
      "grad_norm": 2.853196859359741,
      "learning_rate": 7.157438673233263e-07,
      "loss": 0.545,
      "step": 1580
    },
    {
      "epoch": 1.8228867165037377,
      "grad_norm": 3.3578619956970215,
      "learning_rate": 6.728329474371264e-07,
      "loss": 0.5439,
      "step": 1585
    },
    {
      "epoch": 1.8286371477860839,
      "grad_norm": 5.002884387969971,
      "learning_rate": 6.312189161017101e-07,
      "loss": 0.6046,
      "step": 1590
    },
    {
      "epoch": 1.83438757906843,
      "grad_norm": 4.448881149291992,
      "learning_rate": 5.90905540199988e-07,
      "loss": 0.5262,
      "step": 1595
    },
    {
      "epoch": 1.8401380103507763,
      "grad_norm": 3.513169288635254,
      "learning_rate": 5.518964688801436e-07,
      "loss": 0.5259,
      "step": 1600
    },
    {
      "epoch": 1.8458884416331225,
      "grad_norm": 1.8653478622436523,
      "learning_rate": 5.141952332253197e-07,
      "loss": 0.5152,
      "step": 1605
    },
    {
      "epoch": 1.8516388729154687,
      "grad_norm": 3.44291353225708,
      "learning_rate": 4.778052459339666e-07,
      "loss": 0.639,
      "step": 1610
    },
    {
      "epoch": 1.857389304197815,
      "grad_norm": 3.046926736831665,
      "learning_rate": 4.427298010109432e-07,
      "loss": 0.5816,
      "step": 1615
    },
    {
      "epoch": 1.863139735480161,
      "grad_norm": 3.807365894317627,
      "learning_rate": 4.0897207346934195e-07,
      "loss": 0.5387,
      "step": 1620
    },
    {
      "epoch": 1.8688901667625073,
      "grad_norm": 4.4094672203063965,
      "learning_rate": 3.765351190430838e-07,
      "loss": 0.6348,
      "step": 1625
    },
    {
      "epoch": 1.8746405980448535,
      "grad_norm": 3.13932204246521,
      "learning_rate": 3.45421873910311e-07,
      "loss": 0.5144,
      "step": 1630
    },
    {
      "epoch": 1.8803910293271997,
      "grad_norm": 3.547269582748413,
      "learning_rate": 3.1563515442762314e-07,
      "loss": 0.5851,
      "step": 1635
    },
    {
      "epoch": 1.8861414606095457,
      "grad_norm": 2.099400758743286,
      "learning_rate": 2.8717765687512276e-07,
      "loss": 0.553,
      "step": 1640
    },
    {
      "epoch": 1.8918918918918919,
      "grad_norm": 3.4906108379364014,
      "learning_rate": 2.6005195721235217e-07,
      "loss": 0.5206,
      "step": 1645
    },
    {
      "epoch": 1.897642323174238,
      "grad_norm": 3.9473235607147217,
      "learning_rate": 2.3426051084513512e-07,
      "loss": 0.6334,
      "step": 1650
    },
    {
      "epoch": 1.9033927544565843,
      "grad_norm": 2.570939779281616,
      "learning_rate": 2.0980565240329097e-07,
      "loss": 0.5506,
      "step": 1655
    },
    {
      "epoch": 1.9091431857389303,
      "grad_norm": 3.68090558052063,
      "learning_rate": 1.8668959552932574e-07,
      "loss": 0.5301,
      "step": 1660
    },
    {
      "epoch": 1.9148936170212765,
      "grad_norm": 2.1538121700286865,
      "learning_rate": 1.6491443267803886e-07,
      "loss": 0.5621,
      "step": 1665
    },
    {
      "epoch": 1.9206440483036227,
      "grad_norm": 2.979126214981079,
      "learning_rate": 1.4448213492712636e-07,
      "loss": 0.5416,
      "step": 1670
    },
    {
      "epoch": 1.9263944795859689,
      "grad_norm": 2.8906097412109375,
      "learning_rate": 1.2539455179875038e-07,
      "loss": 0.5309,
      "step": 1675
    },
    {
      "epoch": 1.932144910868315,
      "grad_norm": 3.9377431869506836,
      "learning_rate": 1.0765341109213123e-07,
      "loss": 0.6033,
      "step": 1680
    },
    {
      "epoch": 1.9378953421506613,
      "grad_norm": 2.5090725421905518,
      "learning_rate": 9.12603187271377e-08,
      "loss": 0.5993,
      "step": 1685
    },
    {
      "epoch": 1.9436457734330075,
      "grad_norm": 2.600910186767578,
      "learning_rate": 7.621675859892651e-08,
      "loss": 0.5372,
      "step": 1690
    },
    {
      "epoch": 1.9493962047153537,
      "grad_norm": 5.527241230010986,
      "learning_rate": 6.25240924436199e-08,
      "loss": 0.6551,
      "step": 1695
    },
    {
      "epoch": 1.9551466359976999,
      "grad_norm": 3.629434108734131,
      "learning_rate": 5.018355971503907e-08,
      "loss": 0.5932,
      "step": 1700
    },
    {
      "epoch": 1.960897067280046,
      "grad_norm": 6.327326774597168,
      "learning_rate": 3.919627747251242e-08,
      "loss": 0.6432,
      "step": 1705
    },
    {
      "epoch": 1.9666474985623923,
      "grad_norm": 4.824568748474121,
      "learning_rate": 2.9563240279761316e-08,
      "loss": 0.598,
      "step": 1710
    },
    {
      "epoch": 1.9723979298447385,
      "grad_norm": 2.2919671535491943,
      "learning_rate": 2.1285320114865504e-08,
      "loss": 0.5907,
      "step": 1715
    },
    {
      "epoch": 1.9781483611270847,
      "grad_norm": 9.906854629516602,
      "learning_rate": 1.436326629133955e-08,
      "loss": 0.8583,
      "step": 1720
    },
    {
      "epoch": 1.9838987924094307,
      "grad_norm": 3.9261655807495117,
      "learning_rate": 8.797705390300448e-09,
      "loss": 0.5664,
      "step": 1725
    },
    {
      "epoch": 1.9896492236917769,
      "grad_norm": 2.532254695892334,
      "learning_rate": 4.589141203752978e-09,
      "loss": 0.7726,
      "step": 1730
    },
    {
      "epoch": 1.995399654974123,
      "grad_norm": 4.768822193145752,
      "learning_rate": 1.7379546889861876e-09,
      "loss": 0.5933,
      "step": 1735
    },
    {
      "epoch": 1.9988499137435307,
      "step": 1738,
      "total_flos": 9.603720704604242e+17,
      "train_loss": 0.7541291376252169,
      "train_runtime": 10238.4075,
      "train_samples_per_second": 0.679,
      "train_steps_per_second": 0.17
    }
  ],
  "logging_steps": 5,
  "max_steps": 1738,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 9.603720704604242e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
